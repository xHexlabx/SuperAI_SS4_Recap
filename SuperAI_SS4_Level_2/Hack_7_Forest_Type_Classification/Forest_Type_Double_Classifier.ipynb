{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuperAI Season 4 - Level 2 Hackathon - Forest Type Double Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./datasets/train.csv' , index_col='id')\n",
    "test_df = pd.read_csv('./datasets/test.csv' , index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NON-DEF (MDF / DDF) / DEF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEF_df = train_df[train_df['nforest_type'] == 'DEF']\n",
    "NON_DEF_df = train_df[train_df['nforest_type'] != 'DEF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_DEF_df.to_csv('./datasets/MDF_DDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teehe\\AppData\\Local\\Temp\\ipykernel_22388\\3381345259.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  NON_DEF_df['nforest_type'] = 'NON_DEF'\n",
      "C:\\Users\\teehe\\AppData\\Local\\Temp\\ipykernel_22388\\3381345259.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  DEF_df['nforest_type'] = 'DEF'\n"
     ]
    }
   ],
   "source": [
    "NON_DEF_df['nforest_type'] = 'NON_DEF'\n",
    "DEF_df['nforest_type'] = 'DEF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b8_a</th>\n",
       "      <th>b9</th>\n",
       "      <th>nforest_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>293</td>\n",
       "      <td>1927</td>\n",
       "      <td>1038</td>\n",
       "      <td>278</td>\n",
       "      <td>475</td>\n",
       "      <td>453</td>\n",
       "      <td>987</td>\n",
       "      <td>1773</td>\n",
       "      <td>2184</td>\n",
       "      <td>1900</td>\n",
       "      <td>2343</td>\n",
       "      <td>3039</td>\n",
       "      <td>NON_DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>197</td>\n",
       "      <td>1598</td>\n",
       "      <td>697</td>\n",
       "      <td>201</td>\n",
       "      <td>347</td>\n",
       "      <td>228</td>\n",
       "      <td>682</td>\n",
       "      <td>1982</td>\n",
       "      <td>2449</td>\n",
       "      <td>2254</td>\n",
       "      <td>2685</td>\n",
       "      <td>2690</td>\n",
       "      <td>NON_DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13312</th>\n",
       "      <td>929</td>\n",
       "      <td>1975</td>\n",
       "      <td>1031</td>\n",
       "      <td>982</td>\n",
       "      <td>1020</td>\n",
       "      <td>856</td>\n",
       "      <td>1220</td>\n",
       "      <td>2051</td>\n",
       "      <td>2421</td>\n",
       "      <td>2392</td>\n",
       "      <td>2671</td>\n",
       "      <td>2683</td>\n",
       "      <td>NON_DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17020</th>\n",
       "      <td>132</td>\n",
       "      <td>1560</td>\n",
       "      <td>689</td>\n",
       "      <td>189</td>\n",
       "      <td>408</td>\n",
       "      <td>175</td>\n",
       "      <td>609</td>\n",
       "      <td>2117</td>\n",
       "      <td>2907</td>\n",
       "      <td>3024</td>\n",
       "      <td>3005</td>\n",
       "      <td>2955</td>\n",
       "      <td>NON_DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>241</td>\n",
       "      <td>1944</td>\n",
       "      <td>1131</td>\n",
       "      <td>362</td>\n",
       "      <td>538</td>\n",
       "      <td>487</td>\n",
       "      <td>918</td>\n",
       "      <td>1549</td>\n",
       "      <td>1844</td>\n",
       "      <td>1702</td>\n",
       "      <td>2077</td>\n",
       "      <td>2043</td>\n",
       "      <td>NON_DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9185</th>\n",
       "      <td>374</td>\n",
       "      <td>1940</td>\n",
       "      <td>1054</td>\n",
       "      <td>382</td>\n",
       "      <td>565</td>\n",
       "      <td>498</td>\n",
       "      <td>977</td>\n",
       "      <td>1678</td>\n",
       "      <td>1929</td>\n",
       "      <td>2109</td>\n",
       "      <td>2291</td>\n",
       "      <td>2100</td>\n",
       "      <td>NON_DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13977</th>\n",
       "      <td>1983</td>\n",
       "      <td>3602</td>\n",
       "      <td>2720</td>\n",
       "      <td>1622</td>\n",
       "      <td>1782</td>\n",
       "      <td>1766</td>\n",
       "      <td>2314</td>\n",
       "      <td>3488</td>\n",
       "      <td>3900</td>\n",
       "      <td>3924</td>\n",
       "      <td>4097</td>\n",
       "      <td>6053</td>\n",
       "      <td>NON_DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>940</td>\n",
       "      <td>2007</td>\n",
       "      <td>1148</td>\n",
       "      <td>975</td>\n",
       "      <td>1080</td>\n",
       "      <td>968</td>\n",
       "      <td>1252</td>\n",
       "      <td>1780</td>\n",
       "      <td>1983</td>\n",
       "      <td>1942</td>\n",
       "      <td>2247</td>\n",
       "      <td>2170</td>\n",
       "      <td>NON_DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>1174</td>\n",
       "      <td>2312</td>\n",
       "      <td>1190</td>\n",
       "      <td>1112</td>\n",
       "      <td>1126</td>\n",
       "      <td>889</td>\n",
       "      <td>1310</td>\n",
       "      <td>2511</td>\n",
       "      <td>3085</td>\n",
       "      <td>3050</td>\n",
       "      <td>3396</td>\n",
       "      <td>3380</td>\n",
       "      <td>NON_DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15634</th>\n",
       "      <td>193</td>\n",
       "      <td>2091</td>\n",
       "      <td>1084</td>\n",
       "      <td>274</td>\n",
       "      <td>502</td>\n",
       "      <td>452</td>\n",
       "      <td>881</td>\n",
       "      <td>1953</td>\n",
       "      <td>2427</td>\n",
       "      <td>2830</td>\n",
       "      <td>2863</td>\n",
       "      <td>2586</td>\n",
       "      <td>NON_DEF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10468 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         b1   b11   b12    b2    b3    b4    b5    b6    b7    b8  b8_a    b9  \\\n",
       "id                                                                              \n",
       "2002    293  1927  1038   278   475   453   987  1773  2184  1900  2343  3039   \n",
       "3212    197  1598   697   201   347   228   682  1982  2449  2254  2685  2690   \n",
       "13312   929  1975  1031   982  1020   856  1220  2051  2421  2392  2671  2683   \n",
       "17020   132  1560   689   189   408   175   609  2117  2907  3024  3005  2955   \n",
       "5967    241  1944  1131   362   538   487   918  1549  1844  1702  2077  2043   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "9185    374  1940  1054   382   565   498   977  1678  1929  2109  2291  2100   \n",
       "13977  1983  3602  2720  1622  1782  1766  2314  3488  3900  3924  4097  6053   \n",
       "755     940  2007  1148   975  1080   968  1252  1780  1983  1942  2247  2170   \n",
       "1616   1174  2312  1190  1112  1126   889  1310  2511  3085  3050  3396  3380   \n",
       "15634   193  2091  1084   274   502   452   881  1953  2427  2830  2863  2586   \n",
       "\n",
       "      nforest_type  \n",
       "id                  \n",
       "2002       NON_DEF  \n",
       "3212       NON_DEF  \n",
       "13312      NON_DEF  \n",
       "17020      NON_DEF  \n",
       "5967       NON_DEF  \n",
       "...            ...  \n",
       "9185       NON_DEF  \n",
       "13977      NON_DEF  \n",
       "755        NON_DEF  \n",
       "1616       NON_DEF  \n",
       "15634      NON_DEF  \n",
       "\n",
       "[10468 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NON_DEF_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b8_a</th>\n",
       "      <th>b9</th>\n",
       "      <th>nforest_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14932</th>\n",
       "      <td>701</td>\n",
       "      <td>1776</td>\n",
       "      <td>895</td>\n",
       "      <td>689</td>\n",
       "      <td>905</td>\n",
       "      <td>684</td>\n",
       "      <td>1187</td>\n",
       "      <td>2504</td>\n",
       "      <td>2836</td>\n",
       "      <td>2839</td>\n",
       "      <td>3172</td>\n",
       "      <td>3103</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14572</th>\n",
       "      <td>156</td>\n",
       "      <td>1121</td>\n",
       "      <td>547</td>\n",
       "      <td>264</td>\n",
       "      <td>472</td>\n",
       "      <td>362</td>\n",
       "      <td>699</td>\n",
       "      <td>1673</td>\n",
       "      <td>1967</td>\n",
       "      <td>2182</td>\n",
       "      <td>2260</td>\n",
       "      <td>2277</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>536</td>\n",
       "      <td>1591</td>\n",
       "      <td>777</td>\n",
       "      <td>686</td>\n",
       "      <td>760</td>\n",
       "      <td>624</td>\n",
       "      <td>1049</td>\n",
       "      <td>2152</td>\n",
       "      <td>2600</td>\n",
       "      <td>2665</td>\n",
       "      <td>2964</td>\n",
       "      <td>2777</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10489</th>\n",
       "      <td>1551</td>\n",
       "      <td>1519</td>\n",
       "      <td>718</td>\n",
       "      <td>1730</td>\n",
       "      <td>1764</td>\n",
       "      <td>1514</td>\n",
       "      <td>1719</td>\n",
       "      <td>2267</td>\n",
       "      <td>2554</td>\n",
       "      <td>2598</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>313</td>\n",
       "      <td>1696</td>\n",
       "      <td>864</td>\n",
       "      <td>366</td>\n",
       "      <td>568</td>\n",
       "      <td>411</td>\n",
       "      <td>849</td>\n",
       "      <td>1965</td>\n",
       "      <td>2387</td>\n",
       "      <td>2439</td>\n",
       "      <td>2827</td>\n",
       "      <td>2759</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3762</th>\n",
       "      <td>182</td>\n",
       "      <td>1336</td>\n",
       "      <td>574</td>\n",
       "      <td>188</td>\n",
       "      <td>296</td>\n",
       "      <td>145</td>\n",
       "      <td>571</td>\n",
       "      <td>2000</td>\n",
       "      <td>2473</td>\n",
       "      <td>2243</td>\n",
       "      <td>2884</td>\n",
       "      <td>2844</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804</th>\n",
       "      <td>1</td>\n",
       "      <td>1753</td>\n",
       "      <td>820</td>\n",
       "      <td>106</td>\n",
       "      <td>431</td>\n",
       "      <td>301</td>\n",
       "      <td>840</td>\n",
       "      <td>2091</td>\n",
       "      <td>2472</td>\n",
       "      <td>2762</td>\n",
       "      <td>2914</td>\n",
       "      <td>2440</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>281</td>\n",
       "      <td>1837</td>\n",
       "      <td>835</td>\n",
       "      <td>342</td>\n",
       "      <td>718</td>\n",
       "      <td>285</td>\n",
       "      <td>975</td>\n",
       "      <td>2801</td>\n",
       "      <td>3556</td>\n",
       "      <td>3637</td>\n",
       "      <td>3801</td>\n",
       "      <td>3148</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9311</th>\n",
       "      <td>1656</td>\n",
       "      <td>1955</td>\n",
       "      <td>965</td>\n",
       "      <td>1792</td>\n",
       "      <td>1972</td>\n",
       "      <td>1786</td>\n",
       "      <td>2013</td>\n",
       "      <td>2426</td>\n",
       "      <td>2637</td>\n",
       "      <td>2570</td>\n",
       "      <td>2839</td>\n",
       "      <td>2825</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16941</th>\n",
       "      <td>594</td>\n",
       "      <td>1480</td>\n",
       "      <td>692</td>\n",
       "      <td>620</td>\n",
       "      <td>694</td>\n",
       "      <td>566</td>\n",
       "      <td>847</td>\n",
       "      <td>1833</td>\n",
       "      <td>2489</td>\n",
       "      <td>2779</td>\n",
       "      <td>2684</td>\n",
       "      <td>2799</td>\n",
       "      <td>DEF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2585 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         b1   b11  b12    b2    b3    b4    b5    b6    b7    b8  b8_a    b9  \\\n",
       "id                                                                             \n",
       "14932   701  1776  895   689   905   684  1187  2504  2836  2839  3172  3103   \n",
       "14572   156  1121  547   264   472   362   699  1673  1967  2182  2260  2277   \n",
       "7504    536  1591  777   686   760   624  1049  2152  2600  2665  2964  2777   \n",
       "10489  1551  1519  718  1730  1764  1514  1719  2267  2554  2598  2743  2743   \n",
       "7995    313  1696  864   366   568   411   849  1965  2387  2439  2827  2759   \n",
       "...     ...   ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "3762    182  1336  574   188   296   145   571  2000  2473  2243  2884  2844   \n",
       "7804      1  1753  820   106   431   301   840  2091  2472  2762  2914  2440   \n",
       "5566    281  1837  835   342   718   285   975  2801  3556  3637  3801  3148   \n",
       "9311   1656  1955  965  1792  1972  1786  2013  2426  2637  2570  2839  2825   \n",
       "16941   594  1480  692   620   694   566   847  1833  2489  2779  2684  2799   \n",
       "\n",
       "      nforest_type  \n",
       "id                  \n",
       "14932          DEF  \n",
       "14572          DEF  \n",
       "7504           DEF  \n",
       "10489          DEF  \n",
       "7995           DEF  \n",
       "...            ...  \n",
       "3762           DEF  \n",
       "7804           DEF  \n",
       "5566           DEF  \n",
       "9311           DEF  \n",
       "16941          DEF  \n",
       "\n",
       "[2585 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEF_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEF_NONDEF_df = pd.concat([NON_DEF_df , DEF_df])\n",
    "DEF_NONDEF_df.sort_index().to_csv('./datasets/DEF_NONDEF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEF_NONDEF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEF_NONDEF_df = pd.read_csv('./datasets/DEF_NONDEF.csv' , index_col='id')\n",
    "test_df = pd.read_csv('./datasets/test_cleaned.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_for_DEF_NONDEF(row) :\n",
    "\n",
    "    row['NDVI'] = (row['b8'] - row['b4']) / (row['b8'] + row['b4'])\n",
    "    row['EVI'] = 2.5 * ((row['b8'] - row['b4']) / (row['b8'] + 6 * row['b4'] - 7.5 * row['b2'] + 1.01))\n",
    "    row['NDWI '] = (row['b3'] - row['b8']) / (row['b3'] + row['b8'])\n",
    "    row['SAVI '] = (row['b8'] - row['b4']) * (1 + 0.5) / (row['b8'] + row['b4'] + 0.5)\n",
    "    row['MSAVI'] = (2 * row['b8'] + 1 - ( (2 * row['b8'] + 1) ** 2 - 8 * (row['b8'] - row['b4'])) ** (1 / 2)) / 2\n",
    "    row['GNDVI '] = (row['b8'] - row['b3']) / (row['b8'] + row['b3'])\n",
    "    row['RENDVI '] = (row['b8'] - row['b5']) / (row['b8'] + row['b5'])\n",
    "    row['NDMI '] = (row['b8'] - row['b11']) / (row['b8'] + row['b11'])\n",
    "    row['GRVI'] = (row['b3'] - row['b4']) / (row['b3'] + row['b4'])\n",
    "    row['TVI'] = ( (row['b8'] - row['b4']) / (row['b8'] + row['b4'] + 0.5) ) ** (1 / 2)\n",
    "    row['MCARI'] = ((row['b5'] - row['b4']) - 0.2 * (row['b5'] - row['b3'])) / (row['b5'] / row['b4'])\n",
    "    row['BSI'] =  ((row['b11'] + row['b4']) - (row['b8'] + row['b2'])) / ((row['b11'] + row['b4']) + (row['b8'] + row['b2']))\n",
    "    row['NBR'] = (row['b8'] - row['b12']) / (row['b8'] + row['b12'])\n",
    "    row['MSI'] = row['b11'] / row['b8']\n",
    "\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEF_NONDEF_df = DEF_NONDEF_df.apply(add_features_for_DEF_NONDEF , axis = 1)\n",
    "test_df = test_df.apply(add_features_for_DEF_NONDEF , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nforest_type\n",
       "NON_DEF    10468\n",
       "DEF         2585\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEF_NONDEF_df['nforest_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 199, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\anaconda\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state = 42 , sampling_strategy= 'all')\n",
    "\n",
    "DEF_NONDEF_df , label_df  = smote.fit_resample(DEF_NONDEF_df.drop(columns=['nforest_type']) , DEF_NONDEF_df['nforest_type'])\n",
    "DEF_NONDEF_df = DEF_NONDEF_df.join(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nforest_type\n",
       "NON_DEF    10468\n",
       "DEF        10468\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEF_NONDEF_df['nforest_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240608_063616\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240608_063616\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       0.97 GB / 15.28 GB (6.4%)\n",
      "Disk Space Avail:   545.29 GB / 952.03 GB (57.3%)\n",
      "===================================================\n",
      "Train Data Rows:    20936\n",
      "Train Data Columns: 26\n",
      "Label Column:       nforest_type\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['NON_DEF', 'DEF']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = NON_DEF, class 0 = DEF\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (NON_DEF) vs negative (DEF) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1003.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.15 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['NDVI', 'EVI', 'NDWI ', 'SAVI ', 'MSAVI', ...]\n",
      "\t\t('int', [])   : 12 | ['b1', 'b11', 'b12', 'b2', 'b3', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['NDVI', 'EVI', 'NDWI ', 'SAVI ', 'MSAVI', ...]\n",
      "\t\t('int', [])   : 12 | ['b1', 'b11', 'b12', 'b2', 'b3', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t26 features in original data used to generate 26 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.15 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 18842, Val Rows: 2094\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.8988\t = Validation score   (accuracy)\n",
      "\t3.5s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.9083\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.0864374\n",
      "[2000]\tvalid_set's binary_error: 0.0687679\n",
      "[3000]\tvalid_set's binary_error: 0.0592168\n",
      "[4000]\tvalid_set's binary_error: 0.0573066\n",
      "[5000]\tvalid_set's binary_error: 0.056829\n",
      "[6000]\tvalid_set's binary_error: 0.0563515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9465\t = Validation score   (accuracy)\n",
      "\t10.7s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "Warning: Low available memory may cause OOM error if training continues\n",
      "Available Memory: 507 MB\n",
      "Estimated GBM model size: 0 MB\n",
      "Warning: Early stopped GBM model prior to optimal result to avoid OOM error. Please increase available memory to avoid subpar model quality.\n",
      "\t0.8214\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9207\t = Validation score   (accuracy)\n",
      "\t3.93s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9226\t = Validation score   (accuracy)\n",
      "\t6.06s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.9451\t = Validation score   (accuracy)\n",
      "\t62.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 264 due to low memory. Expected memory usage reduced from 17.0% -> 15.0% of available memory...\n",
      "\t0.9222\t = Validation score   (accuracy)\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 265 due to low memory. Expected memory usage reduced from 16.98% -> 15.0% of available memory...\n",
      "\t0.9217\t = Validation score   (accuracy)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9136\t = Validation score   (accuracy)\n",
      "\t28.54s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9394\t = Validation score   (accuracy)\n",
      "\t4.18s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.9494\t = Validation score   (accuracy)\n",
      "\t142.88s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.0582617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9446\t = Validation score   (accuracy)\n",
      "\t8.29s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.308, 'KNeighborsDist': 0.154, 'RandomForestGini': 0.154, 'CatBoost': 0.154, 'LightGBMXT': 0.077, 'RandomForestEntr': 0.077, 'ExtraTreesGini': 0.077}\n",
      "\t0.9599\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 277.12s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240608_063616\")\n"
     ]
    }
   ],
   "source": [
    "label = 'nforest_type'\n",
    "predictor = TabularPredictor(label = label).fit(DEF_NONDEF_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsUnif_FULL ...\n",
      "\t0.03s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsDist_FULL ...\n",
      "\t0.03s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_FULL ...\n",
      "\t7.37s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_FULL ...\n",
      "\t0.38s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestGini_FULL ...\n",
      "\t3.51s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestEntr_FULL ...\n",
      "\t4.89s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_FULL ...\n",
      "\t40.84s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesGini_FULL ...\n",
      "\t1.7s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesEntr_FULL ...\n",
      "\t1.27s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_FULL ...\n",
      "No improvement since epoch 3: early stopping\n",
      "\t21.35s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_FULL ...\n",
      "\t3.3s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_FULL ...\n",
      "\t125.3s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_FULL ...\n",
      "\t7.49s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.308, 'KNeighborsDist': 0.154, 'RandomForestGini': 0.154, 'CatBoost': 0.154, 'LightGBMXT': 0.077, 'RandomForestEntr': 0.077, 'ExtraTreesGini': 0.077}\n",
      "\t0.15s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 222.92s ... Best model: \"WeightedEnsemble_L2_FULL\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNeighborsUnif': 'KNeighborsUnif_FULL',\n",
       " 'KNeighborsDist': 'KNeighborsDist_FULL',\n",
       " 'LightGBMXT': 'LightGBMXT_FULL',\n",
       " 'LightGBM': 'LightGBM_FULL',\n",
       " 'RandomForestGini': 'RandomForestGini_FULL',\n",
       " 'RandomForestEntr': 'RandomForestEntr_FULL',\n",
       " 'CatBoost': 'CatBoost_FULL',\n",
       " 'ExtraTreesGini': 'ExtraTreesGini_FULL',\n",
       " 'ExtraTreesEntr': 'ExtraTreesEntr_FULL',\n",
       " 'NeuralNetFastAI': 'NeuralNetFastAI_FULL',\n",
       " 'XGBoost': 'XGBoost_FULL',\n",
       " 'NeuralNetTorch': 'NeuralNetTorch_FULL',\n",
       " 'LightGBMLarge': 'LightGBMLarge_FULL',\n",
       " 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.refit_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Given test_data for pseudo labeling did not contain labels. AutoGluon will assign pseudo labels to data and use it for extra training data...\n",
      "Beginning iteration 1 of pseudolabeling out of max 3\n",
      "Pseudolabeling algorithm confidently assigned pseudolabels to 450 rows of data on iteration 1. Adding to train data\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_PSEUDO_1 ...\n",
      "\t0.8997\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_PSEUDO_1 ...\n",
      "\t0.9093\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_PSEUDO_1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.0840497\n",
      "[2000]\tvalid_set's binary_error: 0.0644699\n",
      "[3000]\tvalid_set's binary_error: 0.0596944\n",
      "[4000]\tvalid_set's binary_error: 0.056829\n",
      "[5000]\tvalid_set's binary_error: 0.056829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9446\t = Validation score   (accuracy)\n",
      "\t10.71s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_PSEUDO_1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.0625597\n",
      "[2000]\tvalid_set's binary_error: 0.056829\n",
      "[3000]\tvalid_set's binary_error: 0.0558739\n",
      "[4000]\tvalid_set's binary_error: 0.0477555\n",
      "[5000]\tvalid_set's binary_error: 0.0496657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9527\t = Validation score   (accuracy)\n",
      "\t9.08s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_PSEUDO_1 ...\n",
      "\t0.9212\t = Validation score   (accuracy)\n",
      "\t3.04s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_PSEUDO_1 ...\n",
      "\t0.9222\t = Validation score   (accuracy)\n",
      "\t4.06s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_PSEUDO_1 ...\n",
      "\t0.9422\t = Validation score   (accuracy)\n",
      "\t68.63s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_PSEUDO_1 ...\n",
      "\t0.9183\t = Validation score   (accuracy)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_PSEUDO_1 ...\n",
      "\t0.9226\t = Validation score   (accuracy)\n",
      "\t1.63s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_PSEUDO_1 ...\n",
      "\t0.9198\t = Validation score   (accuracy)\n",
      "\t40.39s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_PSEUDO_1 ...\n",
      "\t0.9422\t = Validation score   (accuracy)\n",
      "\t10.48s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_PSEUDO_1 ...\n",
      "\t0.9494\t = Validation score   (accuracy)\n",
      "\t111.54s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_PSEUDO_1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.0587393\n",
      "[2000]\tvalid_set's binary_error: 0.0534862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9475\t = Validation score   (accuracy)\n",
      "\t17.72s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2_PSEUDO_1 ...\n",
      "\tEnsemble Weights: {'LightGBM_PSEUDO_1': 0.5, 'NeuralNetTorch_PSEUDO_1': 0.5}\n",
      "\t0.9585\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240608_063616\")\n",
      "Pseudolabeling algorithm changed validation score from: 0.9598853868194842, to: 0.9598853868194842 using evaluation metric: accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x19cab49e810>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_pseudolabel(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 26 features using 5000 rows with 5 shuffle sets...\n",
      "\t202.3s\t= Expected runtime (40.46s per shuffle set)\n",
      "\t71.58s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b11</th>\n",
       "      <td>0.25124</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>9.123557e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259831</td>\n",
       "      <td>0.242649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8_a</th>\n",
       "      <td>0.16972</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>1.077205e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.175769</td>\n",
       "      <td>0.163671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b9</th>\n",
       "      <td>0.11052</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>6.015070e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.116576</td>\n",
       "      <td>0.104464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6</th>\n",
       "      <td>0.09864</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>8.874563e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.109241</td>\n",
       "      <td>0.088039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b12</th>\n",
       "      <td>0.08704</td>\n",
       "      <td>0.005642</td>\n",
       "      <td>2.106181e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.098656</td>\n",
       "      <td>0.075424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b5</th>\n",
       "      <td>0.08236</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>1.587799e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.085595</td>\n",
       "      <td>0.079125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b7</th>\n",
       "      <td>0.07664</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>1.559867e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.086127</td>\n",
       "      <td>0.067153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.06904</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>9.014391e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.076489</td>\n",
       "      <td>0.061591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8</th>\n",
       "      <td>0.06040</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>5.593030e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.070699</td>\n",
       "      <td>0.050101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRVI</th>\n",
       "      <td>0.05792</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>5.050901e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.063325</td>\n",
       "      <td>0.052515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBR</th>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>3.320683e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.059227</td>\n",
       "      <td>0.043813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.04940</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>7.086604e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>0.044382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCARI</th>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>1.976714e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.051680</td>\n",
       "      <td>0.039680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENDVI</th>\n",
       "      <td>0.04008</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>2.009705e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045366</td>\n",
       "      <td>0.034794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3</th>\n",
       "      <td>0.02040</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>8.109723e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.024219</td>\n",
       "      <td>0.016581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4</th>\n",
       "      <td>0.01636</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>1.803250e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020105</td>\n",
       "      <td>0.012615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDMI</th>\n",
       "      <td>0.01572</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>5.673019e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.010912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVI</th>\n",
       "      <td>0.01244</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>1.287445e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013908</td>\n",
       "      <td>0.010972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSI</th>\n",
       "      <td>0.00948</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>1.645490e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013283</td>\n",
       "      <td>0.005677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSI</th>\n",
       "      <td>0.00728</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>4.573877e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSAVI</th>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>1.629631e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.001799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GNDVI</th>\n",
       "      <td>0.00228</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>1.891734e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>0.001332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDWI</th>\n",
       "      <td>0.00224</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.603667e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.001347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVI</th>\n",
       "      <td>0.00172</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>1.383980e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.001352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDVI</th>\n",
       "      <td>0.00152</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>6.038645e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.000666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAVI</th>\n",
       "      <td>0.00124</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>5.404130e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance    stddev       p_value  n  p99_high   p99_low\n",
       "b11         0.25124  0.004172  9.123557e-09  5  0.259831  0.242649\n",
       "b8_a        0.16972  0.002938  1.077205e-08  5  0.175769  0.163671\n",
       "b9          0.11052  0.002941  6.015070e-08  5  0.116576  0.104464\n",
       "b6          0.09864  0.005149  8.874563e-07  5  0.109241  0.088039\n",
       "b12         0.08704  0.005642  2.106181e-06  5  0.098656  0.075424\n",
       "b5          0.08236  0.001571  1.587799e-08  5  0.085595  0.079125\n",
       "b7          0.07664  0.004607  1.559867e-06  5  0.086127  0.067153\n",
       "b1          0.06904  0.003618  9.014391e-07  5  0.076489  0.061591\n",
       "b8          0.06040  0.005002  5.593030e-06  5  0.070699  0.050101\n",
       "GRVI        0.05792  0.002625  5.050901e-07  5  0.063325  0.052515\n",
       "NBR         0.05152  0.003743  3.320683e-06  5  0.059227  0.043813\n",
       "b2          0.04940  0.002437  7.086604e-07  5  0.054418  0.044382\n",
       "MCARI       0.04568  0.002914  1.976714e-06  5  0.051680  0.039680\n",
       "RENDVI      0.04008  0.002567  2.009705e-06  5  0.045366  0.034794\n",
       "b3          0.02040  0.001855  8.109723e-06  5  0.024219  0.016581\n",
       "b4          0.01636  0.001819  1.803250e-05  5  0.020105  0.012615\n",
       "NDMI        0.01572  0.002335  5.673019e-05  5  0.020528  0.010912\n",
       "EVI         0.01244  0.000713  1.287445e-06  5  0.013908  0.010972\n",
       "MSI         0.00948  0.001847  1.645490e-04  5  0.013283  0.005677\n",
       "BSI         0.00728  0.001847  4.573877e-04  5  0.011083  0.003477\n",
       "MSAVI       0.00300  0.000583  1.629631e-04  5  0.004201  0.001799\n",
       "GNDVI       0.00228  0.000460  1.891734e-04  5  0.003228  0.001332\n",
       "NDWI        0.00224  0.000434  1.603667e-04  5  0.003133  0.001347\n",
       "TVI         0.00172  0.000179  1.383980e-05  5  0.002088  0.001352\n",
       "NDVI        0.00152  0.000415  6.038645e-04  5  0.002374  0.000666\n",
       "SAVI        0.00124  0.000329  5.404130e-04  5  0.001917  0.000563"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = predictor.feature_importance(DEF_NONDEF_df)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.to_csv('./features/DEF_NONDEF_features_importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nforest_type\n",
       "NON_DEF    3012\n",
       "DEF         988\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1        NON_DEF\n",
       "2        NON_DEF\n",
       "5        NON_DEF\n",
       "7        NON_DEF\n",
       "12           DEF\n",
       "          ...   \n",
       "17039    NON_DEF\n",
       "17042    NON_DEF\n",
       "17043    NON_DEF\n",
       "17047    NON_DEF\n",
       "17052    NON_DEF\n",
       "Name: nforest_type, Length: 4000, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "12       DEF\n",
       "19       DEF\n",
       "29       DEF\n",
       "50       DEF\n",
       "51       DEF\n",
       "        ... \n",
       "17013    DEF\n",
       "17024    DEF\n",
       "17026    DEF\n",
       "17032    DEF\n",
       "17034    DEF\n",
       "Name: nforest_type, Length: 988, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_DEF_ONLY = prediction[prediction == 'DEF']\n",
    "prediction_DEF_ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDF_DDF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./datasets/test_cleaned.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teehe\\AppData\\Local\\Temp\\ipykernel_22388\\254591184.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test_df = test_df[prediction == 'NON_DEF']\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df[prediction == 'NON_DEF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDF_DDF_df = pd.read_csv('./datasets/MDF_DDF.csv' , index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_for_MDF_DDF(row) :\n",
    "\n",
    "    row['NDVI'] = (row['b8'] - row['b4']) / (row['b8'] + row['b4'])\n",
    "    row['EVI'] = 2.5 * ((row['b8'] - row['b4']) / (row['b8'] + 6 * row['b4'] - 7.5 * row['b2'] + 1.01))\n",
    "    row['NDWI '] = (row['b3'] - row['b8']) / (row['b3'] + row['b8'])\n",
    "    row['SAVI '] = (row['b8'] - row['b4']) * (1 + 0.5) / (row['b8'] + row['b4'] + 0.5)\n",
    "    row['MSAVI'] = (2 * row['b8'] + 1 - ( (2 * row['b8'] + 1) ** 2 - 8 * (row['b8'] - row['b4'])) ** (1 / 2)) / 2\n",
    "    row['GNDVI '] = (row['b8'] - row['b3']) / (row['b8'] + row['b3'])\n",
    "    row['RENDVI '] = (row['b8'] - row['b5']) / (row['b8'] + row['b5'])\n",
    "    row['NDMI '] = (row['b8'] - row['b11']) / (row['b8'] + row['b11'])\n",
    "    row['GRVI'] = (row['b3'] - row['b4']) / (row['b3'] + row['b4'])\n",
    "    row['TVI'] = ( (row['b8'] - row['b4']) / (row['b8'] + row['b4'] + 0.5) ) ** (1 / 2)\n",
    "    row['MCARI'] = ((row['b5'] - row['b4']) - 0.2 * (row['b5'] - row['b3'])) / (row['b5'] / row['b4'])\n",
    "    row['BSI'] =  ((row['b11'] + row['b4']) - (row['b8'] + row['b2'])) / ((row['b11'] + row['b4']) + (row['b8'] + row['b2']))\n",
    "    row['NBR'] = (row['b8'] - row['b12']) / (row['b8'] + row['b12'])\n",
    "    row['MSI'] = row['b11'] / row['b8']\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDF_DDF_df = MDF_DDF_df.apply(add_features_for_MDF_DDF , axis = 1)\n",
    "test_df = test_df.apply(add_features_for_MDF_DDF , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nforest_type\n",
       "MDF    5865\n",
       "DDF    4603\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MDF_DDF_df['nforest_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "smote = SMOTE(random_state = 42 , sampling_strategy= 'all')\n",
    "\n",
    "MDF_DDF_df , label_df  = smote.fit_resample(MDF_DDF_df.drop(columns=['nforest_type']) , MDF_DDF_df['nforest_type'])\n",
    "MDF_DDF_df = MDF_DDF_df.join(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nforest_type\n",
       "MDF    5865\n",
       "DDF    5865\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MDF_DDF_df['nforest_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240608_065123\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240608_065123\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       2.64 GB / 15.28 GB (17.3%)\n",
      "Disk Space Avail:   542.64 GB / 952.03 GB (57.0%)\n",
      "===================================================\n",
      "Train Data Rows:    11730\n",
      "Train Data Columns: 26\n",
      "Label Column:       nforest_type\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['MDF', 'DDF']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = MDF, class 0 = DDF\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (MDF) vs negative (DDF) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2703.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.33 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['NDVI', 'EVI', 'NDWI ', 'SAVI ', 'MSAVI', ...]\n",
      "\t\t('int', [])   : 12 | ['b1', 'b11', 'b12', 'b2', 'b3', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['NDVI', 'EVI', 'NDWI ', 'SAVI ', 'MSAVI', ...]\n",
      "\t\t('int', [])   : 12 | ['b1', 'b11', 'b12', 'b2', 'b3', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t26 features in original data used to generate 26 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.33 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10557, Val Rows: 1173\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.7272\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7425\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.244672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7621\t = Validation score   (accuracy)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.236999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7681\t = Validation score   (accuracy)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7613\t = Validation score   (accuracy)\n",
      "\t1.93s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7579\t = Validation score   (accuracy)\n",
      "\t2.76s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.7442\t = Validation score   (accuracy)\n",
      "\t9.13s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7656\t = Validation score   (accuracy)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7621\t = Validation score   (accuracy)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7596\t = Validation score   (accuracy)\n",
      "\t12.51s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7613\t = Validation score   (accuracy)\n",
      "\t4.38s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7749\t = Validation score   (accuracy)\n",
      "\t38.4s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.7749\t = Validation score   (accuracy)\n",
      "\t2.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'KNeighborsDist': 0.286, 'NeuralNetFastAI': 0.238, 'NeuralNetTorch': 0.238, 'RandomForestGini': 0.19, 'KNeighborsUnif': 0.048}\n",
      "\t0.798\t = Validation score   (accuracy)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 79.2s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240608_065123\")\n"
     ]
    }
   ],
   "source": [
    "predictor_for_MDF_DDF = TabularPredictor(label = label).fit(MDF_DDF_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsUnif_FULL ...\n",
      "\t0.02s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsDist_FULL ...\n",
      "\t0.02s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_FULL ...\n",
      "\t1.47s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_FULL ...\n",
      "\t1.12s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestGini_FULL ...\n",
      "\t2.13s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestEntr_FULL ...\n",
      "\t3.04s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_FULL ...\n",
      "\t5.03s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesGini_FULL ...\n",
      "\t1.29s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesEntr_FULL ...\n",
      "\t1.3s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t8.67s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_FULL ...\n",
      "\t2.87s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_FULL ...\n",
      "\t33.08s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_FULL ...\n",
      "\t1.72s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'KNeighborsDist': 0.286, 'NeuralNetFastAI': 0.238, 'NeuralNetTorch': 0.238, 'RandomForestGini': 0.19, 'KNeighborsUnif': 0.048}\n",
      "\t0.1s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 65.2s ... Best model: \"WeightedEnsemble_L2_FULL\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNeighborsUnif': 'KNeighborsUnif_FULL',\n",
       " 'KNeighborsDist': 'KNeighborsDist_FULL',\n",
       " 'LightGBMXT': 'LightGBMXT_FULL',\n",
       " 'LightGBM': 'LightGBM_FULL',\n",
       " 'RandomForestGini': 'RandomForestGini_FULL',\n",
       " 'RandomForestEntr': 'RandomForestEntr_FULL',\n",
       " 'CatBoost': 'CatBoost_FULL',\n",
       " 'ExtraTreesGini': 'ExtraTreesGini_FULL',\n",
       " 'ExtraTreesEntr': 'ExtraTreesEntr_FULL',\n",
       " 'NeuralNetFastAI': 'NeuralNetFastAI_FULL',\n",
       " 'XGBoost': 'XGBoost_FULL',\n",
       " 'NeuralNetTorch': 'NeuralNetTorch_FULL',\n",
       " 'LightGBMLarge': 'LightGBMLarge_FULL',\n",
       " 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_for_MDF_DDF.refit_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Given test_data for pseudo labeling did not contain labels. AutoGluon will assign pseudo labels to data and use it for extra training data...\n",
      "Beginning iteration 1 of pseudolabeling out of max 3\n",
      "Pseudolabeling algorithm confidently assigned pseudolabels to 98 rows of data on iteration 1. Adding to train data\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_PSEUDO_1 ...\n",
      "\t0.7272\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_PSEUDO_1 ...\n",
      "\t0.7425\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_PSEUDO_1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.244672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7596\t = Validation score   (accuracy)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_PSEUDO_1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.232737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7707\t = Validation score   (accuracy)\n",
      "\t3.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_PSEUDO_1 ...\n",
      "\t0.7587\t = Validation score   (accuracy)\n",
      "\t1.87s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_PSEUDO_1 ...\n",
      "\t0.7587\t = Validation score   (accuracy)\n",
      "\t2.59s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_PSEUDO_1 ...\n",
      "\t0.7604\t = Validation score   (accuracy)\n",
      "\t17.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_PSEUDO_1 ...\n",
      "\t0.7673\t = Validation score   (accuracy)\n",
      "\t1.31s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_PSEUDO_1 ...\n",
      "\t0.7664\t = Validation score   (accuracy)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_PSEUDO_1 ...\n",
      "\t0.7639\t = Validation score   (accuracy)\n",
      "\t12.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost_PSEUDO_1 ...\n",
      "\t0.7613\t = Validation score   (accuracy)\n",
      "\t2.65s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_PSEUDO_1 ...\n",
      "\t0.7835\t = Validation score   (accuracy)\n",
      "\t49.97s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_PSEUDO_1 ...\n",
      "\t0.7732\t = Validation score   (accuracy)\n",
      "\t2.5s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2_PSEUDO_1 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch_PSEUDO_1': 0.333, 'ExtraTreesEntr_PSEUDO_1': 0.19, 'KNeighborsDist_PSEUDO_1': 0.143, 'NeuralNetFastAI_PSEUDO_1': 0.143, 'LightGBM_PSEUDO_1': 0.095, 'ExtraTreesGini_PSEUDO_1': 0.095}\n",
      "\t0.7988\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240608_065123\")\n",
      "Pseudolabeling algorithm changed validation score from: 0.7979539641943734, to: 0.7979539641943734 using evaluation metric: accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x19cc1792b10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_for_MDF_DDF.fit_pseudolabel(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_MDF_DDF = predictor_for_MDF_DDF.predict(add_features_for_MDF_DDF( test_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 26 features using 5000 rows with 5 shuffle sets...\n",
      "\t91.18s\t= Expected runtime (18.24s per shuffle set)\n",
      "\t32.58s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b9</th>\n",
       "      <td>0.29700</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>3.955062e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.311655</td>\n",
       "      <td>0.282345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b7</th>\n",
       "      <td>0.21980</td>\n",
       "      <td>0.004656</td>\n",
       "      <td>2.415067e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.229387</td>\n",
       "      <td>0.210213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8</th>\n",
       "      <td>0.21920</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>4.355793e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.230280</td>\n",
       "      <td>0.208120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b12</th>\n",
       "      <td>0.20924</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>3.468958e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.219232</td>\n",
       "      <td>0.199248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b11</th>\n",
       "      <td>0.20688</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>6.815888e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.218577</td>\n",
       "      <td>0.195183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8_a</th>\n",
       "      <td>0.19356</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>3.055580e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.209489</td>\n",
       "      <td>0.177631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b5</th>\n",
       "      <td>0.19172</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>7.022599e-10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.195173</td>\n",
       "      <td>0.188267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6</th>\n",
       "      <td>0.17880</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>3.285856e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.193784</td>\n",
       "      <td>0.163816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.13400</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>1.955282e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.143862</td>\n",
       "      <td>0.124138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3</th>\n",
       "      <td>0.13316</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>1.505168e-10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.134792</td>\n",
       "      <td>0.131528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4</th>\n",
       "      <td>0.12660</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>4.761287e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.133144</td>\n",
       "      <td>0.120056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.12096</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>8.731841e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.128236</td>\n",
       "      <td>0.113684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCARI</th>\n",
       "      <td>0.07164</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>2.170124e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.077052</td>\n",
       "      <td>0.066228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRVI</th>\n",
       "      <td>0.01256</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>5.010549e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.016282</td>\n",
       "      <td>0.008838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVI</th>\n",
       "      <td>0.00884</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>8.426600e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011829</td>\n",
       "      <td>0.005851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSI</th>\n",
       "      <td>0.00832</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>3.832616e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010624</td>\n",
       "      <td>0.006016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSI</th>\n",
       "      <td>0.00812</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>1.292249e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>0.005058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBR</th>\n",
       "      <td>0.00780</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>7.435794e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010355</td>\n",
       "      <td>0.005245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENDVI</th>\n",
       "      <td>0.00756</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>1.762980e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010647</td>\n",
       "      <td>0.004473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDWI</th>\n",
       "      <td>0.00688</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>5.426714e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.003122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDMI</th>\n",
       "      <td>0.00680</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>1.339455e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.004212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVI</th>\n",
       "      <td>0.00576</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>1.023187e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007807</td>\n",
       "      <td>0.003713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDVI</th>\n",
       "      <td>0.00508</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>2.105656e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007251</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GNDVI</th>\n",
       "      <td>0.00472</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>2.333017e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.002649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSAVI</th>\n",
       "      <td>0.00420</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>1.599231e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.002527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAVI</th>\n",
       "      <td>0.00296</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>4.028728e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.001464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance    stddev       p_value  n  p99_high   p99_low\n",
       "b9          0.29700  0.007118  3.955062e-08  5  0.311655  0.282345\n",
       "b7          0.21980  0.004656  2.415067e-08  5  0.229387  0.210213\n",
       "b8          0.21920  0.005381  4.355793e-08  5  0.230280  0.208120\n",
       "b12         0.20924  0.004853  3.468958e-08  5  0.219232  0.199248\n",
       "b11         0.20688  0.005681  6.815888e-08  5  0.218577  0.195183\n",
       "b8_a        0.19356  0.007736  3.055580e-07  5  0.209489  0.177631\n",
       "b5          0.19172  0.001677  7.022599e-10  5  0.195173  0.188267\n",
       "b6          0.17880  0.007277  3.285856e-07  5  0.193784  0.163816\n",
       "b1          0.13400  0.004790  1.955282e-07  5  0.143862  0.124138\n",
       "b3          0.13316  0.000792  1.505168e-10  5  0.134792  0.131528\n",
       "b4          0.12660  0.003178  4.761287e-08  5  0.133144  0.120056\n",
       "b2          0.12096  0.003534  8.731841e-08  5  0.128236  0.113684\n",
       "MCARI       0.07164  0.002628  2.170124e-07  5  0.077052  0.066228\n",
       "GRVI        0.01256  0.001808  5.010549e-05  5  0.016282  0.008838\n",
       "EVI         0.00884  0.001452  8.426600e-05  5  0.011829  0.005851\n",
       "MSI         0.00832  0.001119  3.832616e-05  5  0.010624  0.006016\n",
       "BSI         0.00812  0.001487  1.292249e-04  5  0.011182  0.005058\n",
       "NBR         0.00780  0.001241  7.435794e-05  5  0.010355  0.005245\n",
       "RENDVI      0.00756  0.001499  1.762980e-04  5  0.010647  0.004473\n",
       "NDWI        0.00688  0.001825  5.426714e-04  5  0.010638  0.003122\n",
       "NDMI        0.00680  0.001257  1.339455e-04  5  0.009388  0.004212\n",
       "TVI         0.00576  0.000994  1.023187e-04  5  0.007807  0.003713\n",
       "NDVI        0.00508  0.001055  2.105656e-04  5  0.007251  0.002909\n",
       "GNDVI       0.00472  0.001006  2.333017e-04  5  0.006791  0.002649\n",
       "MSAVI       0.00420  0.000812  1.599231e-04  5  0.005873  0.002527\n",
       "SAVI        0.00296  0.000727  4.028728e-04  5  0.004456  0.001464"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = predictor_for_MDF_DDF.feature_importance(MDF_DDF_df)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.to_csv('./features/MDF_DDF_features_importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nforest_type\n",
       "DDF    1611\n",
       "MDF    1401\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_MDF_DDF.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1        MDF\n",
       "2        DDF\n",
       "5        MDF\n",
       "7        DDF\n",
       "12       DEF\n",
       "        ... \n",
       "17039    DDF\n",
       "17042    DDF\n",
       "17043    DDF\n",
       "17047    MDF\n",
       "17052    DDF\n",
       "Name: nforest_type, Length: 4000, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.concat([prediction_DEF_ONLY , prediction_MDF_DDF])\n",
    "submission_df = submission_df.sort_index()\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nforest_type\n",
       "DDF    1611\n",
       "MDF    1401\n",
       "DEF     988\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = './submissions'\n",
    "submission_df.to_csv(f'{submission_path}/submission_addfeatures_SMOTE_pseudolabeling_double.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
