{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuperAI Season 4 - Level 2 Hackathon - Forest Type Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./datasets/train.csv' )\n",
    "test_df = pd.read_csv('./datasets/test.csv' , index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>b1</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b8_a</th>\n",
       "      <th>b9</th>\n",
       "      <th>nforest_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>293</td>\n",
       "      <td>1927</td>\n",
       "      <td>1038</td>\n",
       "      <td>278</td>\n",
       "      <td>475</td>\n",
       "      <td>453</td>\n",
       "      <td>987</td>\n",
       "      <td>1773</td>\n",
       "      <td>2184</td>\n",
       "      <td>1900</td>\n",
       "      <td>2343</td>\n",
       "      <td>3039</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3212</td>\n",
       "      <td>197</td>\n",
       "      <td>1598</td>\n",
       "      <td>697</td>\n",
       "      <td>201</td>\n",
       "      <td>347</td>\n",
       "      <td>228</td>\n",
       "      <td>682</td>\n",
       "      <td>1982</td>\n",
       "      <td>2449</td>\n",
       "      <td>2254</td>\n",
       "      <td>2685</td>\n",
       "      <td>2690</td>\n",
       "      <td>DDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13312</td>\n",
       "      <td>929</td>\n",
       "      <td>1975</td>\n",
       "      <td>1031</td>\n",
       "      <td>982</td>\n",
       "      <td>1020</td>\n",
       "      <td>856</td>\n",
       "      <td>1220</td>\n",
       "      <td>2051</td>\n",
       "      <td>2421</td>\n",
       "      <td>2392</td>\n",
       "      <td>2671</td>\n",
       "      <td>2683</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17020</td>\n",
       "      <td>132</td>\n",
       "      <td>1560</td>\n",
       "      <td>689</td>\n",
       "      <td>189</td>\n",
       "      <td>408</td>\n",
       "      <td>175</td>\n",
       "      <td>609</td>\n",
       "      <td>2117</td>\n",
       "      <td>2907</td>\n",
       "      <td>3024</td>\n",
       "      <td>3005</td>\n",
       "      <td>2955</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5967</td>\n",
       "      <td>241</td>\n",
       "      <td>1944</td>\n",
       "      <td>1131</td>\n",
       "      <td>362</td>\n",
       "      <td>538</td>\n",
       "      <td>487</td>\n",
       "      <td>918</td>\n",
       "      <td>1549</td>\n",
       "      <td>1844</td>\n",
       "      <td>1702</td>\n",
       "      <td>2077</td>\n",
       "      <td>2043</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13048</th>\n",
       "      <td>9185</td>\n",
       "      <td>374</td>\n",
       "      <td>1940</td>\n",
       "      <td>1054</td>\n",
       "      <td>382</td>\n",
       "      <td>565</td>\n",
       "      <td>498</td>\n",
       "      <td>977</td>\n",
       "      <td>1678</td>\n",
       "      <td>1929</td>\n",
       "      <td>2109</td>\n",
       "      <td>2291</td>\n",
       "      <td>2100</td>\n",
       "      <td>DDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13049</th>\n",
       "      <td>13977</td>\n",
       "      <td>1983</td>\n",
       "      <td>3602</td>\n",
       "      <td>2720</td>\n",
       "      <td>1622</td>\n",
       "      <td>1782</td>\n",
       "      <td>1766</td>\n",
       "      <td>2314</td>\n",
       "      <td>3488</td>\n",
       "      <td>3900</td>\n",
       "      <td>3924</td>\n",
       "      <td>4097</td>\n",
       "      <td>6053</td>\n",
       "      <td>DDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13050</th>\n",
       "      <td>755</td>\n",
       "      <td>940</td>\n",
       "      <td>2007</td>\n",
       "      <td>1148</td>\n",
       "      <td>975</td>\n",
       "      <td>1080</td>\n",
       "      <td>968</td>\n",
       "      <td>1252</td>\n",
       "      <td>1780</td>\n",
       "      <td>1983</td>\n",
       "      <td>1942</td>\n",
       "      <td>2247</td>\n",
       "      <td>2170</td>\n",
       "      <td>DDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13051</th>\n",
       "      <td>1616</td>\n",
       "      <td>1174</td>\n",
       "      <td>2312</td>\n",
       "      <td>1190</td>\n",
       "      <td>1112</td>\n",
       "      <td>1126</td>\n",
       "      <td>889</td>\n",
       "      <td>1310</td>\n",
       "      <td>2511</td>\n",
       "      <td>3085</td>\n",
       "      <td>3050</td>\n",
       "      <td>3396</td>\n",
       "      <td>3380</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13052</th>\n",
       "      <td>15634</td>\n",
       "      <td>193</td>\n",
       "      <td>2091</td>\n",
       "      <td>1084</td>\n",
       "      <td>274</td>\n",
       "      <td>502</td>\n",
       "      <td>452</td>\n",
       "      <td>881</td>\n",
       "      <td>1953</td>\n",
       "      <td>2427</td>\n",
       "      <td>2830</td>\n",
       "      <td>2863</td>\n",
       "      <td>2586</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13053 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    b1   b11   b12    b2    b3    b4    b5    b6    b7    b8  \\\n",
       "0       2002   293  1927  1038   278   475   453   987  1773  2184  1900   \n",
       "1       3212   197  1598   697   201   347   228   682  1982  2449  2254   \n",
       "2      13312   929  1975  1031   982  1020   856  1220  2051  2421  2392   \n",
       "3      17020   132  1560   689   189   408   175   609  2117  2907  3024   \n",
       "4       5967   241  1944  1131   362   538   487   918  1549  1844  1702   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "13048   9185   374  1940  1054   382   565   498   977  1678  1929  2109   \n",
       "13049  13977  1983  3602  2720  1622  1782  1766  2314  3488  3900  3924   \n",
       "13050    755   940  2007  1148   975  1080   968  1252  1780  1983  1942   \n",
       "13051   1616  1174  2312  1190  1112  1126   889  1310  2511  3085  3050   \n",
       "13052  15634   193  2091  1084   274   502   452   881  1953  2427  2830   \n",
       "\n",
       "       b8_a    b9 nforest_type  \n",
       "0      2343  3039          MDF  \n",
       "1      2685  2690          DDF  \n",
       "2      2671  2683          MDF  \n",
       "3      3005  2955          MDF  \n",
       "4      2077  2043          MDF  \n",
       "...     ...   ...          ...  \n",
       "13048  2291  2100          DDF  \n",
       "13049  4097  6053          DDF  \n",
       "13050  2247  2170          DDF  \n",
       "13051  3396  3380          MDF  \n",
       "13052  2863  2586          MDF  \n",
       "\n",
       "[13053 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b8_a</th>\n",
       "      <th>b9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13467</th>\n",
       "      <td>69</td>\n",
       "      <td>1425</td>\n",
       "      <td>693</td>\n",
       "      <td>312</td>\n",
       "      <td>524</td>\n",
       "      <td>376</td>\n",
       "      <td>847</td>\n",
       "      <td>1821</td>\n",
       "      <td>2356</td>\n",
       "      <td>2378</td>\n",
       "      <td>2611</td>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12719</th>\n",
       "      <td>242</td>\n",
       "      <td>1514</td>\n",
       "      <td>691</td>\n",
       "      <td>343</td>\n",
       "      <td>522</td>\n",
       "      <td>324</td>\n",
       "      <td>718</td>\n",
       "      <td>1730</td>\n",
       "      <td>2178</td>\n",
       "      <td>2472</td>\n",
       "      <td>2359</td>\n",
       "      <td>2582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>218</td>\n",
       "      <td>2354</td>\n",
       "      <td>1118</td>\n",
       "      <td>292</td>\n",
       "      <td>596</td>\n",
       "      <td>410</td>\n",
       "      <td>965</td>\n",
       "      <td>2586</td>\n",
       "      <td>3226</td>\n",
       "      <td>3371</td>\n",
       "      <td>3645</td>\n",
       "      <td>3149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13747</th>\n",
       "      <td>350</td>\n",
       "      <td>2013</td>\n",
       "      <td>1134</td>\n",
       "      <td>306</td>\n",
       "      <td>572</td>\n",
       "      <td>475</td>\n",
       "      <td>982</td>\n",
       "      <td>1754</td>\n",
       "      <td>1935</td>\n",
       "      <td>2275</td>\n",
       "      <td>2290</td>\n",
       "      <td>2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9453</th>\n",
       "      <td>185</td>\n",
       "      <td>1450</td>\n",
       "      <td>712</td>\n",
       "      <td>293</td>\n",
       "      <td>440</td>\n",
       "      <td>384</td>\n",
       "      <td>673</td>\n",
       "      <td>1487</td>\n",
       "      <td>1965</td>\n",
       "      <td>2213</td>\n",
       "      <td>2200</td>\n",
       "      <td>2193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>447</td>\n",
       "      <td>1686</td>\n",
       "      <td>811</td>\n",
       "      <td>425</td>\n",
       "      <td>661</td>\n",
       "      <td>441</td>\n",
       "      <td>958</td>\n",
       "      <td>2432</td>\n",
       "      <td>2891</td>\n",
       "      <td>2966</td>\n",
       "      <td>3126</td>\n",
       "      <td>3312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10654</th>\n",
       "      <td>252</td>\n",
       "      <td>2694</td>\n",
       "      <td>1503</td>\n",
       "      <td>470</td>\n",
       "      <td>778</td>\n",
       "      <td>753</td>\n",
       "      <td>1294</td>\n",
       "      <td>2334</td>\n",
       "      <td>2656</td>\n",
       "      <td>2679</td>\n",
       "      <td>3212</td>\n",
       "      <td>2856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>233</td>\n",
       "      <td>1486</td>\n",
       "      <td>618</td>\n",
       "      <td>249</td>\n",
       "      <td>409</td>\n",
       "      <td>260</td>\n",
       "      <td>699</td>\n",
       "      <td>2188</td>\n",
       "      <td>2831</td>\n",
       "      <td>3030</td>\n",
       "      <td>3086</td>\n",
       "      <td>3087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13054</th>\n",
       "      <td>221</td>\n",
       "      <td>1840</td>\n",
       "      <td>774</td>\n",
       "      <td>245</td>\n",
       "      <td>441</td>\n",
       "      <td>231</td>\n",
       "      <td>703</td>\n",
       "      <td>2491</td>\n",
       "      <td>3453</td>\n",
       "      <td>3284</td>\n",
       "      <td>3762</td>\n",
       "      <td>3161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6539</th>\n",
       "      <td>2</td>\n",
       "      <td>1431</td>\n",
       "      <td>629</td>\n",
       "      <td>140</td>\n",
       "      <td>373</td>\n",
       "      <td>254</td>\n",
       "      <td>596</td>\n",
       "      <td>1740</td>\n",
       "      <td>2436</td>\n",
       "      <td>2113</td>\n",
       "      <td>2645</td>\n",
       "      <td>2630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        b1   b11   b12   b2   b3   b4    b5    b6    b7    b8  b8_a    b9\n",
       "id                                                                       \n",
       "13467   69  1425   693  312  524  376   847  1821  2356  2378  2611  2595\n",
       "12719  242  1514   691  343  522  324   718  1730  2178  2472  2359  2582\n",
       "1054   218  2354  1118  292  596  410   965  2586  3226  3371  3645  3149\n",
       "13747  350  2013  1134  306  572  475   982  1754  1935  2275  2290  2345\n",
       "9453   185  1450   712  293  440  384   673  1487  1965  2213  2200  2193\n",
       "...    ...   ...   ...  ...  ...  ...   ...   ...   ...   ...   ...   ...\n",
       "115    447  1686   811  425  661  441   958  2432  2891  2966  3126  3312\n",
       "10654  252  2694  1503  470  778  753  1294  2334  2656  2679  3212  2856\n",
       "5718   233  1486   618  249  409  260   699  2188  2831  3030  3086  3087\n",
       "13054  221  1840   774  245  441  231   703  2491  3453  3284  3762  3161\n",
       "6539     2  1431   629  140  373  254   596  1740  2436  2113  2645  2630\n",
       "\n",
       "[4000 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Engineer / SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b8_a</th>\n",
       "      <th>b9</th>\n",
       "      <th>nforest_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>293</td>\n",
       "      <td>1927</td>\n",
       "      <td>1038</td>\n",
       "      <td>278</td>\n",
       "      <td>475</td>\n",
       "      <td>453</td>\n",
       "      <td>987</td>\n",
       "      <td>1773</td>\n",
       "      <td>2184</td>\n",
       "      <td>1900</td>\n",
       "      <td>2343</td>\n",
       "      <td>3039</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>197</td>\n",
       "      <td>1598</td>\n",
       "      <td>697</td>\n",
       "      <td>201</td>\n",
       "      <td>347</td>\n",
       "      <td>228</td>\n",
       "      <td>682</td>\n",
       "      <td>1982</td>\n",
       "      <td>2449</td>\n",
       "      <td>2254</td>\n",
       "      <td>2685</td>\n",
       "      <td>2690</td>\n",
       "      <td>DDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13312</th>\n",
       "      <td>929</td>\n",
       "      <td>1975</td>\n",
       "      <td>1031</td>\n",
       "      <td>982</td>\n",
       "      <td>1020</td>\n",
       "      <td>856</td>\n",
       "      <td>1220</td>\n",
       "      <td>2051</td>\n",
       "      <td>2421</td>\n",
       "      <td>2392</td>\n",
       "      <td>2671</td>\n",
       "      <td>2683</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17020</th>\n",
       "      <td>132</td>\n",
       "      <td>1560</td>\n",
       "      <td>689</td>\n",
       "      <td>189</td>\n",
       "      <td>408</td>\n",
       "      <td>175</td>\n",
       "      <td>609</td>\n",
       "      <td>2117</td>\n",
       "      <td>2907</td>\n",
       "      <td>3024</td>\n",
       "      <td>3005</td>\n",
       "      <td>2955</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>241</td>\n",
       "      <td>1944</td>\n",
       "      <td>1131</td>\n",
       "      <td>362</td>\n",
       "      <td>538</td>\n",
       "      <td>487</td>\n",
       "      <td>918</td>\n",
       "      <td>1549</td>\n",
       "      <td>1844</td>\n",
       "      <td>1702</td>\n",
       "      <td>2077</td>\n",
       "      <td>2043</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9185</th>\n",
       "      <td>374</td>\n",
       "      <td>1940</td>\n",
       "      <td>1054</td>\n",
       "      <td>382</td>\n",
       "      <td>565</td>\n",
       "      <td>498</td>\n",
       "      <td>977</td>\n",
       "      <td>1678</td>\n",
       "      <td>1929</td>\n",
       "      <td>2109</td>\n",
       "      <td>2291</td>\n",
       "      <td>2100</td>\n",
       "      <td>DDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13977</th>\n",
       "      <td>1983</td>\n",
       "      <td>3602</td>\n",
       "      <td>2720</td>\n",
       "      <td>1622</td>\n",
       "      <td>1782</td>\n",
       "      <td>1766</td>\n",
       "      <td>2314</td>\n",
       "      <td>3488</td>\n",
       "      <td>3900</td>\n",
       "      <td>3924</td>\n",
       "      <td>4097</td>\n",
       "      <td>6053</td>\n",
       "      <td>DDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>940</td>\n",
       "      <td>2007</td>\n",
       "      <td>1148</td>\n",
       "      <td>975</td>\n",
       "      <td>1080</td>\n",
       "      <td>968</td>\n",
       "      <td>1252</td>\n",
       "      <td>1780</td>\n",
       "      <td>1983</td>\n",
       "      <td>1942</td>\n",
       "      <td>2247</td>\n",
       "      <td>2170</td>\n",
       "      <td>DDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>1174</td>\n",
       "      <td>2312</td>\n",
       "      <td>1190</td>\n",
       "      <td>1112</td>\n",
       "      <td>1126</td>\n",
       "      <td>889</td>\n",
       "      <td>1310</td>\n",
       "      <td>2511</td>\n",
       "      <td>3085</td>\n",
       "      <td>3050</td>\n",
       "      <td>3396</td>\n",
       "      <td>3380</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15634</th>\n",
       "      <td>193</td>\n",
       "      <td>2091</td>\n",
       "      <td>1084</td>\n",
       "      <td>274</td>\n",
       "      <td>502</td>\n",
       "      <td>452</td>\n",
       "      <td>881</td>\n",
       "      <td>1953</td>\n",
       "      <td>2427</td>\n",
       "      <td>2830</td>\n",
       "      <td>2863</td>\n",
       "      <td>2586</td>\n",
       "      <td>MDF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13053 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         b1   b11   b12    b2    b3    b4    b5    b6    b7    b8  b8_a    b9  \\\n",
       "id                                                                              \n",
       "2002    293  1927  1038   278   475   453   987  1773  2184  1900  2343  3039   \n",
       "3212    197  1598   697   201   347   228   682  1982  2449  2254  2685  2690   \n",
       "13312   929  1975  1031   982  1020   856  1220  2051  2421  2392  2671  2683   \n",
       "17020   132  1560   689   189   408   175   609  2117  2907  3024  3005  2955   \n",
       "5967    241  1944  1131   362   538   487   918  1549  1844  1702  2077  2043   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "9185    374  1940  1054   382   565   498   977  1678  1929  2109  2291  2100   \n",
       "13977  1983  3602  2720  1622  1782  1766  2314  3488  3900  3924  4097  6053   \n",
       "755     940  2007  1148   975  1080   968  1252  1780  1983  1942  2247  2170   \n",
       "1616   1174  2312  1190  1112  1126   889  1310  2511  3085  3050  3396  3380   \n",
       "15634   193  2091  1084   274   502   452   881  1953  2427  2830  2863  2586   \n",
       "\n",
       "      nforest_type  \n",
       "id                  \n",
       "2002           MDF  \n",
       "3212           DDF  \n",
       "13312          MDF  \n",
       "17020          MDF  \n",
       "5967           MDF  \n",
       "...            ...  \n",
       "9185           DDF  \n",
       "13977          DDF  \n",
       "755            DDF  \n",
       "1616           MDF  \n",
       "15634          MDF  \n",
       "\n",
       "[13053 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nforest_type\n",
       "MDF    5865\n",
       "DDF    4603\n",
       "DEF    2585\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['nforest_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nforest_type\n",
       "MDF    5865\n",
       "DDF    5865\n",
       "DEF    5865\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE , KMeansSMOTE\n",
    "from imblearn.combine import SMOTEENN , SMOTETomek\n",
    "\n",
    "smote = SMOTE(random_state = 42 , sampling_strategy= 'all')\n",
    "\n",
    "train_df , label_df  = smote.fit_resample(train_df.drop(columns=['nforest_type']) , train_df['nforest_type'])\n",
    "train_df = train_df.join(label_df)\n",
    "train_df['nforest_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(row) :\n",
    "\n",
    "    \n",
    "    row['NDVI'] = (row['b8'] - row['b4']) / (row['b8'] + row['b4'])\n",
    "    row['EVI'] = 2.5 * ((row['b8'] - row['b4']) / (row['b8'] + 6 * row['b4'] - 7.5 * row['b2'] + 1.01))\n",
    "    row['NDWI '] = (row['b3'] - row['b8']) / (row['b3'] + row['b8'])\n",
    "    row['SAVI '] = (row['b8'] - row['b4']) * (1 + 0.5) / (row['b8'] + row['b4'] + 0.5)\n",
    "    row['MSAVI'] = (2 * row['b8'] + 1 - ( (2 * row['b8'] + 1) ** 2 - 8 * (row['b8'] - row['b4'])) ** (1 / 2)) / 2\n",
    "    row['GNDVI '] = (row['b8'] - row['b3']) / (row['b8'] + row['b3'])\n",
    "    row['RENDVI '] = (row['b8'] - row['b5']) / (row['b8'] + row['b5'])\n",
    "    row['NDMI '] = (row['b8'] - row['b11']) / (row['b8'] + row['b11'])\n",
    "    row['GRVI'] = (row['b3'] - row['b4']) / (row['b3'] + row['b4'])\n",
    "    row['TVI'] = ( (row['b8'] - row['b4']) / (row['b8'] + row['b4'] + 0.5) ) ** (1 / 2)\n",
    "    row['MCARI'] = ((row['b5'] - row['b4']) - 0.2 * (row['b5'] - row['b3'])) / (row['b5'] / row['b4'])\n",
    "    row['BSI'] =  ((row['b11'] + row['b4']) - (row['b8'] + row['b2'])) / ((row['b11'] + row['b4']) + (row['b8'] + row['b2']))\n",
    "    row['NBR'] = (row['b8'] - row['b12']) / (row['b8'] + row['b12'])\n",
    "    row['MSI'] = row['b11'] / row['b8']\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.apply(add_features , axis = 1)\n",
    "test_df = test_df.apply(add_features , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>...</th>\n",
       "      <th>MSAVI</th>\n",
       "      <th>GNDVI</th>\n",
       "      <th>RENDVI</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>GRVI</th>\n",
       "      <th>TVI</th>\n",
       "      <th>MCARI</th>\n",
       "      <th>BSI</th>\n",
       "      <th>NBR</th>\n",
       "      <th>MSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>1927</td>\n",
       "      <td>1038</td>\n",
       "      <td>278</td>\n",
       "      <td>475</td>\n",
       "      <td>453</td>\n",
       "      <td>987</td>\n",
       "      <td>1773</td>\n",
       "      <td>2184</td>\n",
       "      <td>1900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761531</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.316245</td>\n",
       "      <td>-0.007055</td>\n",
       "      <td>0.023707</td>\n",
       "      <td>0.784110</td>\n",
       "      <td>198.089970</td>\n",
       "      <td>0.044318</td>\n",
       "      <td>0.293397</td>\n",
       "      <td>1.014211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197</td>\n",
       "      <td>1598</td>\n",
       "      <td>697</td>\n",
       "      <td>201</td>\n",
       "      <td>347</td>\n",
       "      <td>228</td>\n",
       "      <td>682</td>\n",
       "      <td>1982</td>\n",
       "      <td>2449</td>\n",
       "      <td>2254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898826</td>\n",
       "      <td>0.733180</td>\n",
       "      <td>0.535422</td>\n",
       "      <td>0.170301</td>\n",
       "      <td>0.206957</td>\n",
       "      <td>0.903390</td>\n",
       "      <td>129.378299</td>\n",
       "      <td>-0.146928</td>\n",
       "      <td>0.527618</td>\n",
       "      <td>0.708962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>929</td>\n",
       "      <td>1975</td>\n",
       "      <td>1031</td>\n",
       "      <td>982</td>\n",
       "      <td>1020</td>\n",
       "      <td>856</td>\n",
       "      <td>1220</td>\n",
       "      <td>2051</td>\n",
       "      <td>2421</td>\n",
       "      <td>2392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642092</td>\n",
       "      <td>0.402110</td>\n",
       "      <td>0.324474</td>\n",
       "      <td>0.095489</td>\n",
       "      <td>0.087420</td>\n",
       "      <td>0.687629</td>\n",
       "      <td>227.331148</td>\n",
       "      <td>-0.087510</td>\n",
       "      <td>0.397604</td>\n",
       "      <td>0.825669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>1560</td>\n",
       "      <td>689</td>\n",
       "      <td>189</td>\n",
       "      <td>408</td>\n",
       "      <td>175</td>\n",
       "      <td>609</td>\n",
       "      <td>2117</td>\n",
       "      <td>2907</td>\n",
       "      <td>3024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942121</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.664740</td>\n",
       "      <td>0.319372</td>\n",
       "      <td>0.399657</td>\n",
       "      <td>0.943637</td>\n",
       "      <td>113.160920</td>\n",
       "      <td>-0.298707</td>\n",
       "      <td>0.628872</td>\n",
       "      <td>0.515873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>241</td>\n",
       "      <td>1944</td>\n",
       "      <td>1131</td>\n",
       "      <td>362</td>\n",
       "      <td>538</td>\n",
       "      <td>487</td>\n",
       "      <td>918</td>\n",
       "      <td>1549</td>\n",
       "      <td>1844</td>\n",
       "      <td>1702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713806</td>\n",
       "      <td>0.519643</td>\n",
       "      <td>0.299237</td>\n",
       "      <td>-0.066374</td>\n",
       "      <td>0.049756</td>\n",
       "      <td>0.744930</td>\n",
       "      <td>188.327887</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>0.201553</td>\n",
       "      <td>1.142186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17590</th>\n",
       "      <td>102</td>\n",
       "      <td>1567</td>\n",
       "      <td>693</td>\n",
       "      <td>210</td>\n",
       "      <td>436</td>\n",
       "      <td>265</td>\n",
       "      <td>706</td>\n",
       "      <td>2227</td>\n",
       "      <td>2717</td>\n",
       "      <td>2951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910186</td>\n",
       "      <td>0.742545</td>\n",
       "      <td>0.613891</td>\n",
       "      <td>0.306330</td>\n",
       "      <td>0.243937</td>\n",
       "      <td>0.913821</td>\n",
       "      <td>145.262040</td>\n",
       "      <td>-0.266173</td>\n",
       "      <td>0.619649</td>\n",
       "      <td>0.531006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>1700</td>\n",
       "      <td>1926</td>\n",
       "      <td>965</td>\n",
       "      <td>1918</td>\n",
       "      <td>1946</td>\n",
       "      <td>1860</td>\n",
       "      <td>2074</td>\n",
       "      <td>2528</td>\n",
       "      <td>2726</td>\n",
       "      <td>2692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309024</td>\n",
       "      <td>0.160845</td>\n",
       "      <td>0.129668</td>\n",
       "      <td>0.165873</td>\n",
       "      <td>0.022596</td>\n",
       "      <td>0.427501</td>\n",
       "      <td>168.960463</td>\n",
       "      <td>-0.098142</td>\n",
       "      <td>0.472245</td>\n",
       "      <td>0.715453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17592</th>\n",
       "      <td>252</td>\n",
       "      <td>1940</td>\n",
       "      <td>990</td>\n",
       "      <td>375</td>\n",
       "      <td>626</td>\n",
       "      <td>471</td>\n",
       "      <td>960</td>\n",
       "      <td>2049</td>\n",
       "      <td>2372</td>\n",
       "      <td>2987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842294</td>\n",
       "      <td>0.653474</td>\n",
       "      <td>0.513555</td>\n",
       "      <td>0.212503</td>\n",
       "      <td>0.141294</td>\n",
       "      <td>0.852926</td>\n",
       "      <td>207.141875</td>\n",
       "      <td>-0.164732</td>\n",
       "      <td>0.502137</td>\n",
       "      <td>0.649481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>419</td>\n",
       "      <td>2185</td>\n",
       "      <td>1225</td>\n",
       "      <td>478</td>\n",
       "      <td>654</td>\n",
       "      <td>647</td>\n",
       "      <td>1049</td>\n",
       "      <td>1862</td>\n",
       "      <td>2167</td>\n",
       "      <td>2183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703571</td>\n",
       "      <td>0.538950</td>\n",
       "      <td>0.350866</td>\n",
       "      <td>-0.000458</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.736655</td>\n",
       "      <td>199.219256</td>\n",
       "      <td>0.031131</td>\n",
       "      <td>0.281103</td>\n",
       "      <td>1.000916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17594</th>\n",
       "      <td>179</td>\n",
       "      <td>1445</td>\n",
       "      <td>633</td>\n",
       "      <td>283</td>\n",
       "      <td>473</td>\n",
       "      <td>275</td>\n",
       "      <td>742</td>\n",
       "      <td>2441</td>\n",
       "      <td>3198</td>\n",
       "      <td>3364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918241</td>\n",
       "      <td>0.753453</td>\n",
       "      <td>0.638578</td>\n",
       "      <td>0.399043</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.921272</td>\n",
       "      <td>153.140162</td>\n",
       "      <td>-0.359046</td>\n",
       "      <td>0.683262</td>\n",
       "      <td>0.429548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17595 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         b1   b11   b12    b2    b3    b4    b5    b6    b7    b8  ...  \\\n",
       "0       293  1927  1038   278   475   453   987  1773  2184  1900  ...   \n",
       "1       197  1598   697   201   347   228   682  1982  2449  2254  ...   \n",
       "2       929  1975  1031   982  1020   856  1220  2051  2421  2392  ...   \n",
       "3       132  1560   689   189   408   175   609  2117  2907  3024  ...   \n",
       "4       241  1944  1131   362   538   487   918  1549  1844  1702  ...   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "17590   102  1567   693   210   436   265   706  2227  2717  2951  ...   \n",
       "17591  1700  1926   965  1918  1946  1860  2074  2528  2726  2692  ...   \n",
       "17592   252  1940   990   375   626   471   960  2049  2372  2987  ...   \n",
       "17593   419  2185  1225   478   654   647  1049  1862  2167  2183  ...   \n",
       "17594   179  1445   633   283   473   275   742  2441  3198  3364  ...   \n",
       "\n",
       "          MSAVI    GNDVI    RENDVI      NDMI       GRVI       TVI       MCARI  \\\n",
       "0      0.761531  0.600000  0.316245 -0.007055  0.023707  0.784110  198.089970   \n",
       "1      0.898826  0.733180  0.535422  0.170301  0.206957  0.903390  129.378299   \n",
       "2      0.642092  0.402110  0.324474  0.095489  0.087420  0.687629  227.331148   \n",
       "3      0.942121  0.762238  0.664740  0.319372  0.399657  0.943637  113.160920   \n",
       "4      0.713806  0.519643  0.299237 -0.066374  0.049756  0.744930  188.327887   \n",
       "...         ...       ...       ...       ...       ...       ...         ...   \n",
       "17590  0.910186  0.742545  0.613891  0.306330  0.243937  0.913821  145.262040   \n",
       "17591  0.309024  0.160845  0.129668  0.165873  0.022596  0.427501  168.960463   \n",
       "17592  0.842294  0.653474  0.513555  0.212503  0.141294  0.852926  207.141875   \n",
       "17593  0.703571  0.538950  0.350866 -0.000458  0.005380  0.736655  199.219256   \n",
       "17594  0.918241  0.753453  0.638578  0.399043  0.264706  0.921272  153.140162   \n",
       "\n",
       "            BSI       NBR       MSI  \n",
       "0      0.044318  0.293397  1.014211  \n",
       "1     -0.146928  0.527618  0.708962  \n",
       "2     -0.087510  0.397604  0.825669  \n",
       "3     -0.298707  0.628872  0.515873  \n",
       "4      0.081646  0.201553  1.142186  \n",
       "...         ...       ...       ...  \n",
       "17590 -0.266173  0.619649  0.531006  \n",
       "17591 -0.098142  0.472245  0.715453  \n",
       "17592 -0.164732  0.502137  0.649481  \n",
       "17593  0.031131  0.281103  1.000916  \n",
       "17594 -0.359046  0.683262  0.429548  \n",
       "\n",
       "[17595 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['b1', 'b11', 'b12', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b8_a',\n",
       "       'b9', 'nforest_type', 'NDVI', 'EVI', 'NDWI ', 'SAVI ', 'MSAVI',\n",
       "       'GNDVI ', 'RENDVI ', 'NDMI ', 'GRVI', 'TVI', 'MCARI', 'BSI', 'NBR',\n",
       "       'MSI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0 : 'MDF' ,\n",
    "    1 : 'DDF' ,\n",
    "    2 : 'DEF' \n",
    "}\n",
    "label2id = {\n",
    "    'MDF' : 0 ,\n",
    "    'DDF' : 1 ,\n",
    "    'DEF' : 2 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label (row) :\n",
    "    \n",
    "    row['nforest_type'] = label2id[row['nforest_type']]\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.apply(convert_label , axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = CatBoostClassifier(learning_rate = 0.1, depth = 12 , n_estimators = 2000 , random_seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_df.drop(columns = 'nforest_type') , train_df['nforest_type'] , test_size = 0.20 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0612791\ttotal: 368ms\tremaining: 12m 15s\n",
      "100:\tlearn: 0.5447309\ttotal: 33.5s\tremaining: 10m 30s\n",
      "200:\tlearn: 0.3987076\ttotal: 1m 5s\tremaining: 9m 49s\n",
      "300:\tlearn: 0.3072528\ttotal: 1m 38s\tremaining: 9m 14s\n",
      "400:\tlearn: 0.2453936\ttotal: 2m 10s\tremaining: 8m 40s\n",
      "500:\tlearn: 0.2006882\ttotal: 2m 43s\tremaining: 8m 9s\n",
      "600:\tlearn: 0.1673098\ttotal: 3m 16s\tremaining: 7m 37s\n",
      "700:\tlearn: 0.1418107\ttotal: 3m 49s\tremaining: 7m 5s\n",
      "800:\tlearn: 0.1215223\ttotal: 4m 22s\tremaining: 6m 33s\n",
      "900:\tlearn: 0.1053827\ttotal: 4m 55s\tremaining: 6m\n",
      "1000:\tlearn: 0.0936261\ttotal: 5m 28s\tremaining: 5m 28s\n",
      "1100:\tlearn: 0.0834695\ttotal: 6m 1s\tremaining: 4m 55s\n",
      "1200:\tlearn: 0.0745525\ttotal: 6m 33s\tremaining: 4m 21s\n",
      "1300:\tlearn: 0.0672307\ttotal: 7m 5s\tremaining: 3m 48s\n",
      "1400:\tlearn: 0.0609461\ttotal: 7m 37s\tremaining: 3m 15s\n",
      "1500:\tlearn: 0.0556334\ttotal: 8m 9s\tremaining: 2m 42s\n",
      "1600:\tlearn: 0.0510121\ttotal: 8m 41s\tremaining: 2m 9s\n",
      "1700:\tlearn: 0.0470197\ttotal: 9m 13s\tremaining: 1m 37s\n",
      "1800:\tlearn: 0.0434707\ttotal: 9m 45s\tremaining: 1m 4s\n",
      "1900:\tlearn: 0.0404285\ttotal: 10m 18s\tremaining: 32.2s\n",
      "1999:\tlearn: 0.0377506\ttotal: 10m 50s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1708cca6650>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_model.fit(x_train , y_train , verbose = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score = 0.789712986643933\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score =' , accuracy_score(catboost_model.predict(x_test) , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [2],\n",
       "       [0],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = XGBClassifier(n_estimators = 2000 , max_depth = 12, learning_rate = 0.1 , objective = 'multi:softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_df.drop(columns = 'nforest_type') , train_df['nforest_type'] , test_size = 0.20 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-18 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-18 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-18 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-18 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-18 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-18 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=12, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=2000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=12, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=2000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=12, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=2000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softmax', ...)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model.fit(x_train , y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score = 0.7908496732026143\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score =' , accuracy_score(xgboost_model.predict(x_test) , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 2, 0, 2])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'nforest_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240608_070541\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240608_070541\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       1.99 GB / 15.28 GB (13.0%)\n",
      "Disk Space Avail:   540.72 GB / 952.03 GB (56.8%)\n",
      "===================================================\n",
      "Train Data Rows:    17595\n",
      "Train Data Columns: 26\n",
      "Label Column:       nforest_type\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['MDF', 'DDF', 'DEF']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2036.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.49 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['NDVI', 'EVI', 'NDWI ', 'SAVI ', 'MSAVI', ...]\n",
      "\t\t('int', [])   : 12 | ['b1', 'b11', 'b12', 'b2', 'b3', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['NDVI', 'EVI', 'NDWI ', 'SAVI ', 'MSAVI', ...]\n",
      "\t\t('int', [])   : 12 | ['b1', 'b11', 'b12', 'b2', 'b3', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t26 features in original data used to generate 26 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.49 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 15835, Val Rows: 1760\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "c:\\anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 199, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\anaconda\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\anaconda\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\t0.7165\t = Validation score   (accuracy)\n",
      "\t6.45s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7557\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.767\t = Validation score   (accuracy)\n",
      "\t25.2s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's multi_error: 0.236364\n",
      "[2000]\tvalid_set's multi_error: 0.217045\n",
      "[3000]\tvalid_set's multi_error: 0.213068\n",
      "[4000]\tvalid_set's multi_error: 0.211932\n",
      "[5000]\tvalid_set's multi_error: 0.208523\n",
      "[6000]\tvalid_set's multi_error: 0.209659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7943\t = Validation score   (accuracy)\n",
      "\t33.41s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's multi_error: 0.226136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7852\t = Validation score   (accuracy)\n",
      "\t11.85s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7602\t = Validation score   (accuracy)\n",
      "\t3.53s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7614\t = Validation score   (accuracy)\n",
      "\t4.98s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.792\t = Validation score   (accuracy)\n",
      "\t356.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7659\t = Validation score   (accuracy)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7534\t = Validation score   (accuracy)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7807\t = Validation score   (accuracy)\n",
      "\t4.6s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7795\t = Validation score   (accuracy)\n",
      "\t44.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.7869\t = Validation score   (accuracy)\n",
      "\t8.81s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'KNeighborsDist': 0.286, 'LightGBMXT': 0.143, 'ExtraTreesGini': 0.143, 'ExtraTreesEntr': 0.143, 'NeuralNetTorch': 0.143, 'LightGBMLarge': 0.143}\n",
      "\t0.8097\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 507.53s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240608_070541\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label = label).fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsUnif_FULL ...\n",
      "\t0.02s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsDist_FULL ...\n",
      "\t0.02s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t9.54s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_FULL ...\n",
      "\t13.45s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_FULL ...\n",
      "\t4.79s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestGini_FULL ...\n",
      "\t3.25s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestEntr_FULL ...\n",
      "\t5.24s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_FULL ...\n",
      "\t153.47s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesGini_FULL ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 297 due to low memory. Expected memory usage reduced from 17.41% -> 17.25% of available memory...\n",
      "\t1.3s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesEntr_FULL ...\n",
      "\t1.57s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_FULL ...\n",
      "\t3.84s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_FULL ...\n",
      "\t59.85s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_FULL ...\n",
      "\t7.55s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'KNeighborsDist': 0.286, 'LightGBMXT': 0.143, 'ExtraTreesGini': 0.143, 'ExtraTreesEntr': 0.143, 'NeuralNetTorch': 0.143, 'LightGBMLarge': 0.143}\n",
      "\t0.12s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 272.39s ... Best model: \"WeightedEnsemble_L2_FULL\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNeighborsUnif': 'KNeighborsUnif_FULL',\n",
       " 'KNeighborsDist': 'KNeighborsDist_FULL',\n",
       " 'NeuralNetFastAI': 'NeuralNetFastAI_FULL',\n",
       " 'LightGBMXT': 'LightGBMXT_FULL',\n",
       " 'LightGBM': 'LightGBM_FULL',\n",
       " 'RandomForestGini': 'RandomForestGini_FULL',\n",
       " 'RandomForestEntr': 'RandomForestEntr_FULL',\n",
       " 'CatBoost': 'CatBoost_FULL',\n",
       " 'ExtraTreesGini': 'ExtraTreesGini_FULL',\n",
       " 'ExtraTreesEntr': 'ExtraTreesEntr_FULL',\n",
       " 'XGBoost': 'XGBoost_FULL',\n",
       " 'NeuralNetTorch': 'NeuralNetTorch_FULL',\n",
       " 'LightGBMLarge': 'LightGBMLarge_FULL',\n",
       " 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.refit_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Given test_data for pseudo labeling did not contain labels. AutoGluon will assign pseudo labels to data and use it for extra training data...\n",
      "Beginning iteration 1 of pseudolabeling out of max 3\n",
      "Pseudolabeling algorithm confidently assigned pseudolabels to 18 rows of data on iteration 1. Adding to train data\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_PSEUDO_1 ...\n",
      "\t0.7159\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_PSEUDO_1 ...\n",
      "\t0.7551\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_PSEUDO_1 ...\n",
      "\t0.767\t = Validation score   (accuracy)\n",
      "\t16.52s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_PSEUDO_1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's multi_error: 0.225568\n",
      "[2000]\tvalid_set's multi_error: 0.214773\n",
      "[3000]\tvalid_set's multi_error: 0.206818\n",
      "[4000]\tvalid_set's multi_error: 0.202841\n",
      "[5000]\tvalid_set's multi_error: 0.202841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8006\t = Validation score   (accuracy)\n",
      "\t14.76s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: LightGBM_PSEUDO_1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's multi_error: 0.222159\n",
      "[2000]\tvalid_set's multi_error: 0.213068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7898\t = Validation score   (accuracy)\n",
      "\t6.38s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_PSEUDO_1 ...\n",
      "\t0.7636\t = Validation score   (accuracy)\n",
      "\t3.03s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_PSEUDO_1 ...\n",
      "\t0.7591\t = Validation score   (accuracy)\n",
      "\t4.55s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_PSEUDO_1 ...\n",
      "\t0.7892\t = Validation score   (accuracy)\n",
      "\t297.56s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_PSEUDO_1 ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 273 due to low memory. Expected memory usage reduced from 16.44% -> 15.0% of available memory...\n",
      "\t0.7551\t = Validation score   (accuracy)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_PSEUDO_1 ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 247 due to low memory. Expected memory usage reduced from 18.17% -> 15.0% of available memory...\n",
      "\t0.7597\t = Validation score   (accuracy)\n",
      "\t1.13s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_PSEUDO_1 ...\n",
      "\t0.7926\t = Validation score   (accuracy)\n",
      "\t16.53s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_PSEUDO_1 ...\n",
      "\t0.7812\t = Validation score   (accuracy)\n",
      "\t43.42s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_PSEUDO_1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's multi_error: 0.208523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7937\t = Validation score   (accuracy)\n",
      "\t12.33s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2_PSEUDO_1 ...\n",
      "\tEnsemble Weights: {'KNeighborsDist_PSEUDO_1': 0.231, 'LightGBMXT_PSEUDO_1': 0.231, 'ExtraTreesGini_PSEUDO_1': 0.154, 'ExtraTreesEntr_PSEUDO_1': 0.154, 'NeuralNetFastAI_PSEUDO_1': 0.077, 'RandomForestGini_PSEUDO_1': 0.077, 'NeuralNetTorch_PSEUDO_1': 0.077}\n",
      "\t0.8108\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240608_070541\")\n",
      "Pseudolabeling algorithm changed validation score from: 0.8096590909090909, to: 0.8096590909090909 using evaluation metric: accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x29bff936b90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_pseudolabel(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "13467    DEF\n",
       "12719    MDF\n",
       "1054     MDF\n",
       "13747    DDF\n",
       "9453     DEF\n",
       "        ... \n",
       "115      MDF\n",
       "10654    MDF\n",
       "5718     DDF\n",
       "13054    MDF\n",
       "6539     DEF\n",
       "Name: nforest_type, Length: 4000, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 26 features using 5000 rows with 5 shuffle sets...\n",
      "\t415.33s\t= Expected runtime (83.07s per shuffle set)\n",
      "\t255.68s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b11</th>\n",
       "      <td>0.23700</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>5.585948e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.249749</td>\n",
       "      <td>0.224251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8_a</th>\n",
       "      <td>0.18632</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>2.809461e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.201334</td>\n",
       "      <td>0.171306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b9</th>\n",
       "      <td>0.18416</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>7.523364e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.194833</td>\n",
       "      <td>0.173487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b7</th>\n",
       "      <td>0.11564</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>2.394538e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.124593</td>\n",
       "      <td>0.106687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6</th>\n",
       "      <td>0.09700</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>7.060593e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.106845</td>\n",
       "      <td>0.087155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8</th>\n",
       "      <td>0.07764</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>3.610453e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.084302</td>\n",
       "      <td>0.070978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b5</th>\n",
       "      <td>0.07108</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>1.478373e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.075958</td>\n",
       "      <td>0.066202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b12</th>\n",
       "      <td>0.06892</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>4.631464e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.080128</td>\n",
       "      <td>0.057712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>1.427404e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.058656</td>\n",
       "      <td>0.051184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.04180</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>8.906906e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.049812</td>\n",
       "      <td>0.033788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3</th>\n",
       "      <td>0.01576</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>3.719686e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018186</td>\n",
       "      <td>0.013334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRVI</th>\n",
       "      <td>0.00948</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>5.172456e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012312</td>\n",
       "      <td>0.006648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b4</th>\n",
       "      <td>0.00904</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>1.373058e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.005577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCARI</th>\n",
       "      <td>0.00904</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>9.931826e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.007259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBR</th>\n",
       "      <td>0.00660</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>1.431685e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.004045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENDVI</th>\n",
       "      <td>0.00172</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>6.882868e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.001168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVI</th>\n",
       "      <td>0.00040</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>5.528247e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>-0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GNDVI</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSAVI</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDMI</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAVI</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVI</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDWI</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSI</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDVI</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSI</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance    stddev       p_value  n  p99_high   p99_low\n",
       "b11         0.23700  0.006192  5.585948e-08  5  0.249749  0.224251\n",
       "b8_a        0.18632  0.007292  2.809461e-07  5  0.201334  0.171306\n",
       "b9          0.18416  0.005183  7.523364e-08  5  0.194833  0.173487\n",
       "b7          0.11564  0.004348  2.394538e-07  5  0.124593  0.106687\n",
       "b6          0.09700  0.004781  7.060593e-07  5  0.106845  0.087155\n",
       "b8          0.07764  0.003235  3.610453e-07  5  0.084302  0.070978\n",
       "b5          0.07108  0.002369  1.478373e-07  5  0.075958  0.066202\n",
       "b12         0.06892  0.005444  4.631464e-06  5  0.080128  0.057712\n",
       "b1          0.05492  0.001814  1.427404e-07  5  0.058656  0.051184\n",
       "b2          0.04180  0.003891  8.906906e-06  5  0.049812  0.033788\n",
       "b3          0.01576  0.001178  3.719686e-06  5  0.018186  0.013334\n",
       "GRVI        0.00948  0.001375  5.172456e-05  5  0.012312  0.006648\n",
       "b4          0.00904  0.001682  1.373058e-04  5  0.012503  0.005577\n",
       "MCARI       0.00904  0.000865  9.931826e-06  5  0.010821  0.007259\n",
       "NBR         0.00660  0.001241  1.431685e-04  5  0.009155  0.004045\n",
       "RENDVI      0.00172  0.000268  6.882868e-05  5  0.002272  0.001168\n",
       "EVI         0.00040  0.000200  5.528247e-03  5  0.000812 -0.000012\n",
       "GNDVI       0.00000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
       "MSAVI       0.00000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
       "NDMI        0.00000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
       "SAVI        0.00000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
       "TVI         0.00000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
       "NDWI        0.00000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
       "BSI         0.00000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
       "NDVI        0.00000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
       "MSI         0.00000  0.000000  5.000000e-01  5  0.000000  0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_importance =predictor.feature_importance(train_df)\n",
    "features_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance.to_csv('./features/features3class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nforest_type\n",
       "DDF    1529\n",
       "MDF    1513\n",
       "DEF     958\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = './submissions'\n",
    "prediction.to_csv(f'{submission_path}/submission_addfeatures_SMOTE_pseudolabeling.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
