{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xHexlabx/SuperAI_SS4_Recap/blob/main/SuperAI_SS4_Level_1/Hack_1_Image_Search/Image_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D4EeLyI2HnZ"
      },
      "source": [
        "# SuperAI Season 4 - Level 1 Hackathon - Image Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhLRzDPlKT9N"
      },
      "source": [
        "# Explore Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AsXt70YNKbBE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fjXdsWKQPKhf"
      },
      "outputs": [],
      "source": [
        "def refine_image (image) :\n",
        "\n",
        "    width = 336\n",
        "    height = 336\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image , (width , height))\n",
        "    image = np.array(image)[: , : , 0 : 3]\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y6gcl4clOmM0"
      },
      "outputs": [],
      "source": [
        "refined_image_path = './datasets/queries/refined_queries'\n",
        "\n",
        "for i in range(22) :\n",
        "\n",
        "    image = cv2.imread(f'./datasets/queries/queries/{i}.jpg')\n",
        "\n",
        "    resized_image = refine_image(image)\n",
        "\n",
        "    with open(f'{refined_image_path}/{i}.npy' , 'wb') as file :\n",
        "\n",
        "        np.save(file , resized_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAspHAXL2Hna"
      },
      "source": [
        "# CLIP VisionModel For Encode Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ylhc8rY7GGw",
        "outputId": "86f208e2-0aac-4fbe-cfb2-6d2c99942d4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'DOSKEY' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vxlaMwsc2Hna"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import AutoProcessor, CLIPModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trKKpB1d2Hnb",
        "outputId": "ca703be7-db70-4825-b0c6-6ab6b82b79c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d02df71aa4b948cabfbff868eff32480",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/4.52k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\teehe\\.cache\\huggingface\\hub\\models--openai--clip-vit-large-patch14. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c92b42b4c4354e62bbc82506478a86da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd2c6fd2b1584abfbc2e0e8dd1a4b131",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06f2c18433f94080b1ec0d55aa2ffc52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8d4e37e5d7048c38ada335a6b216d54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e12b83c020264a4c8c10aa51025ab8f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a9c9e0e6ffe4b738b75b047cda0275d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48e608361e8c49b98cbb5dba5f399f88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = CLIPModel.from_pretrained('openai/clip-vit-large-patch14')\n",
        "processor = AutoProcessor.from_pretrained('openai/clip-vit-large-patch14')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Xl9RkKNr2Hnc"
      },
      "outputs": [],
      "source": [
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NAHttHel2Hnc"
      },
      "outputs": [],
      "source": [
        "inputs = processor(images = image, return_tensors = \"pt\")\n",
        "image_features = model.get_image_features(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubsIgpO12Hnc",
        "outputId": "6f935e7d-772f-478e-d8d1-a0276384dfe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPdjHemB2Hnd"
      },
      "source": [
        "# Solution-CLIP Zeroshot For Image Similarity Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3DCaUkj2Hnd"
      },
      "source": [
        "## Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yZptx9qp2Hne"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch import nn\n",
        "\n",
        "def cosine_similarity (A , B) :\n",
        "\n",
        "    A = np.array(A)\n",
        "    B = np.array(B)\n",
        "\n",
        "    norm_A = np.linalg.norm(A)\n",
        "\n",
        "    similarity_matrix = (A @ B.T).astype('float32') / norm_A\n",
        "\n",
        "    for i in range(B.shape[0]) :\n",
        "\n",
        "        norm_B = np.linalg.norm(B[i])\n",
        "\n",
        "        similarity_matrix[0][i] /= norm_B\n",
        "\n",
        "    similarity_matrix = similarity_matrix.reshape(-1)\n",
        "\n",
        "    # softmax\n",
        "    # similarity_matrix = np.exp(similarity_matrix)/sum(np.exp(similarity_matrix))\n",
        "\n",
        "    target_class = similarity_matrix.argmax(axis = 0)\n",
        "    maximum_similarity = similarity_matrix[target_class]\n",
        "\n",
        "    return maximum_similarity , target_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnDP_2Ha4y5U",
        "outputId": "411ed0ab-6340-474c-dee3-a8c1a517b6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.99999994, 0)\n"
          ]
        }
      ],
      "source": [
        "print(cosine_similarity(np.array([[1 , 2  ,3]]) , np.array([[1 , 2 , 3] , [3 , 4 , 5]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uVdwPmW2Hne"
      },
      "source": [
        "## Define Model CLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3UyyK9jv2Hnf"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import AutoProcessor , CLIPModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KziDkp9Bk7OM"
      },
      "source": [
        "## openai/clip-vit-large-patch14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4cIr0HCmw_TU"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jmm2dKxB2Hnf"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = CLIPModel.from_pretrained('openai/clip-vit-large-patch14').to(device)\n",
        "processor = AutoProcessor.from_pretrained('openai/clip-vit-large-patch14')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDSrXcby2Hnf"
      },
      "source": [
        "## Read queries folder image and store to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "P33PiTk42Hnf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Wjn9CX0S2Hnf"
      },
      "outputs": [],
      "source": [
        "refined_queries_path = './datasets/queries/refined_queries'\n",
        "images = []\n",
        "\n",
        "for file_name in os.listdir(refined_queries_path) :\n",
        "\n",
        "    with open(f'{refined_queries_path}/{file_name}' , 'rb') as file :\n",
        "\n",
        "        image = np.load(file)\n",
        "\n",
        "    images.append(image)\n",
        "\n",
        "inputs = processor(images = images , return_tensors = 'pt').to(device)\n",
        "image_features = model.get_image_features(** inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vRFyso0z2Hng"
      },
      "outputs": [],
      "source": [
        "image_features = image_features.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PAS0zT892Hng"
      },
      "outputs": [],
      "source": [
        "with open('./database/queries_matrix.npy' , 'wb') as file :\n",
        "\n",
        "    np.save(file , image_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ednldmyf2Hng"
      },
      "source": [
        "## Read test folder images to inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ryCtyi7O2Hng"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "G012beBJ2Hnh"
      },
      "outputs": [],
      "source": [
        "with open('./database/queries_matrix.npy' , 'rb') as file :\n",
        "\n",
        "    queries_matrix = np.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rp3eNW12Hnh",
        "outputId": "bdff3033-a82c-4d04-fa01-713ff7b866e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(22, 768)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "queries_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Fn9btcmA2Hnh"
      },
      "outputs": [],
      "source": [
        "submissions = {\n",
        "    'img_file' : [] ,\n",
        "    'class' : []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "31x1xIWgc0Wl"
      },
      "outputs": [],
      "source": [
        "threshold = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFfxGctgc4PU",
        "outputId": "f0480d72-76ac-4c4d-ca7d-7b6a2ee7a410"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1120/1120 [23:14<00:00,  1.25s/it]\n"
          ]
        }
      ],
      "source": [
        "test_path = './datasets/test/images'\n",
        "\n",
        "for file_name in tqdm(os.listdir(test_path)) :\n",
        "\n",
        "    image = cv2.imread(f'{test_path}/{file_name}')\n",
        "    image = refine_image(image)\n",
        "\n",
        "    inputs = processor(images = image , return_tensors = 'pt').to(device)\n",
        "    image_features = model.get_image_features(** inputs)\n",
        "\n",
        "    maximum_similarity , target_class = cosine_similarity(image_features.cpu().detach().numpy() , queries_matrix )\n",
        "\n",
        "    threshold += maximum_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8hSKQESc-k_",
        "outputId": "83269566-5f04-4f8e-fc51-03bb1f49683f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8226966738700867"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "threshold /= 1120\n",
        "threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb7bEOCL2Hni",
        "outputId": "9b4c5638-3f9c-4132-aa32-b785f5d01481"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1120/1120 [26:51<00:00,  1.44s/it]\n"
          ]
        }
      ],
      "source": [
        "test_path = './datasets/test/images'\n",
        "\n",
        "for file_name in tqdm(os.listdir(test_path)) :\n",
        "\n",
        "    image = cv2.imread(f'{test_path}/{file_name}')\n",
        "    image = refine_image(image)\n",
        "\n",
        "    inputs = processor(images = image , return_tensors = 'pt').to(device)\n",
        "    image_features = model.get_image_features(** inputs)\n",
        "\n",
        "    maximum_similarity , target_class = cosine_similarity(image_features.cpu().detach().numpy() , queries_matrix )\n",
        "\n",
        "    if maximum_similarity < threshold :\n",
        "\n",
        "        target_class = 22\n",
        "\n",
        "    submissions['img_file'].append(file_name)\n",
        "    submissions['class'].append(target_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "JM26bi1BF8uY"
      },
      "outputs": [],
      "source": [
        "submissions = pd.DataFrame.from_dict(submissions)\n",
        "submissions_path = './submissions/submissions.csv'\n",
        "\n",
        "with open(submissions_path, 'w') as csv_file:\n",
        "\n",
        "    submissions.to_csv(path_or_buf = csv_file , index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "OgIEU2rPZ4ph",
        "outputId": "9d1fa8df-c9f8-42d4-b4fc-ebac83b97d06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_file</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>476</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       img_file\n",
              "class          \n",
              "0             4\n",
              "1            42\n",
              "2            68\n",
              "3             8\n",
              "4             1\n",
              "5             6\n",
              "6            20\n",
              "7             3\n",
              "10           10\n",
              "11            1\n",
              "12            2\n",
              "13          194\n",
              "14            3\n",
              "15          114\n",
              "16            4\n",
              "17           63\n",
              "18           24\n",
              "19            2\n",
              "20            1\n",
              "21           74\n",
              "22          476"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submissions.groupby('class').count()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
